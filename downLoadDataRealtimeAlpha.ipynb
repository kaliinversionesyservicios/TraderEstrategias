{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1e400e-66ea-4231-b554-33216632364e",
   "metadata": {},
   "source": [
    "### Descarga Realtime Alpha Vantage\n",
    "###### Descarga cada 10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59056cd-968d-485d-84e7-d0777e5435ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import date, datetime,timedelta\n",
    "#from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si el archivo existe\n",
    "ruta_archivo='data/dataxd.txt'\n",
    "if os.path.exists(ruta_archivo):\n",
    "    # Cargar el archivo\n",
    "    df1 = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "else:\n",
    "    # Crear un DataFrame vacío\n",
    "    df1 = pd.DataFrame()\n",
    "    print(\"Archivo no existe. Se creó un DataFrame vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377b8ac-a9ef-4fa4-88fc-48d9332e4a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "ruta_archivo='data/dataxh.txt'\n",
    "if os.path.exists(ruta_archivo):\n",
    "    # Cargar el archivo\n",
    "    df2 = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "else:\n",
    "    # Crear un DataFrame vacío\n",
    "    df2 = pd.DataFrame()\n",
    "    print(\"Archivo no existe. Se creó un DataFrame vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "df2['datetime'] = pd.to_datetime(df2['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_day1 = (df1['datetime'].max()).date()\n",
    "max_day2 = (df2['datetime'].max()).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_day2 = max_day2 - timedelta(days=5) #para Realtime restar 5 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c159857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today = date.today()\n",
    "max_day_str2 = str(max_day2)\n",
    "max_day_str1 = str(max_day1)\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META',\n",
    "    'AAPL',\n",
    "    'AMZN',\n",
    "    'NFLX',\n",
    "    'MRNA',\n",
    "    'TSLA',\n",
    "    'TNA',\n",
    "    'GLD',\n",
    "    'SLV',\n",
    "    'USO',\n",
    "    'BAC',\n",
    "    'CVX',\n",
    "    'XOM',\n",
    "    'QQQ',\n",
    "    'MSFT',\n",
    "    'NVDA',\n",
    "    'WMT',\n",
    "    'BA',\n",
    "    'DIS',\n",
    "    'CAT',\n",
    "    'IBM',\n",
    "    'WFC',\n",
    "    'PLTR',\n",
    "    'AMD',\n",
    "    'AVGO',\n",
    "    'HOOD',\n",
    "    'CRWV',\n",
    "    'MSTR',\n",
    "    'UNH',\n",
    "    'GOOG',\n",
    "    'APP',\n",
    "    'UBER'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFORMACION DIAS\n",
    "df_new1 = pd.DataFrame()\n",
    "df_new1 = df1.copy()\n",
    "for ticker in tickers:\n",
    "    url1='https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol='+str(ticker)+'&entitlement=delayed&apikey=HR9C4MJVM7O4UUCM&datatype=csv'\n",
    "    company = pd.read_csv(url1, sep=',')\n",
    "    company=company.rename(columns={'timestamp':'datetime','open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})\n",
    "    company = company.drop(['adjusted_close','dividend_amount','split_coefficient'], axis=1)\n",
    "    company['companyName']=ticker\n",
    "    company = company[['Close', 'High', 'Low', 'Open', 'Volume', 'datetime', 'companyName']] #ordenar columnas\n",
    "    company['datetime'] = pd.to_datetime(company['datetime'])\n",
    "    company_lastday = company[company['datetime']>max_day_str1]\n",
    "    df_new1 = pd.concat([df_new1, company_lastday],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca35012-6da3-4775-8beb-b59a5cc61ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion limpiar OUTLIERS\n",
    "def df_limpiar(df_eval):\n",
    "    #dataframe para obtener medias sin incluir fecha actual\n",
    "    df_eval2 = df_eval[df_eval['datetime']<max_day_str2].tail(100)\n",
    "    \n",
    "    meandif1 = df_eval2['dif1'].mean()\n",
    "    stddif1 = df_eval2['dif1'].std()\n",
    "    topdif1 = meandif1 + stddif1 * 1.96\n",
    "\n",
    "    meandif2 = df_eval2['dif2'].mean()\n",
    "    stddif2 = df_eval2['dif2'].std()\n",
    "    topdif2 = meandif2 + stddif2 * 1.96\n",
    "    \n",
    "    #botdif = meandif - stddif * 3\n",
    "    copydf = df_eval.copy()\n",
    "    \n",
    "    #df_h.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    copydf['ind1'] = copydf.apply(lambda row: 1 if row['dif1'] > topdif1 else 0, axis=1)\n",
    "    copydf['ind2'] = copydf.apply(lambda row: 1 if row['dif2'] > topdif2 else 0, axis=1)\n",
    "\n",
    "    #hoy = datetime.now()    \n",
    "    #mes_actual = hoy.replace(day=1)\n",
    "    #mes_fin = mes_actual - relativedelta(months=3)\n",
    "    #hace_12_meses = mes_actual - relativedelta(months=12)\n",
    "    #cuartil 3\n",
    "    q3_dif1 = copydf[copydf['ind1']!=1]['dif1'].quantile(0.75)\n",
    "    q3_dif2 = copydf[copydf['ind2']!=1]['dif2'].quantile(0.75)\n",
    "    \n",
    "    #meanfin1 = copydf[(copydf['ind1']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif1'].mean()\n",
    "    #meanfin2 = copydf[(copydf['ind2']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif2'].mean()\n",
    "\n",
    "    print(\"q3_dif1:\",q3_dif1)\n",
    "    print(\"q3_dif2:\",q3_dif2)\n",
    "\n",
    "    copydf['High2']=copydf.apply(\n",
    "        lambda row: row['Close'] + q3_dif1 if (row['Close'] > row['Open']) & (row['ind1']==1) & (row['eval']==0)  else \n",
    "        row['Open'] + q3_dif1 if (row['Close'] <= row['Open']) & (row['ind1']==1) & (row['eval']==0) else\n",
    "        row['High'], axis=1)\n",
    "    copydf['Low2']=copydf.apply(\n",
    "        lambda row: row['Open'] - q3_dif2 if (row['Close'] > row['Open']) & (row['ind2']==1) & (row['eval']==0) else \n",
    "        row['Close'] - q3_dif2 if (row['Close'] <= row['Open']) & (row['ind2']==1) & (row['eval']==0) else\n",
    "        row['Low'], axis=1)\n",
    "   \n",
    "    #copydf = copydf.drop(copydf[copydf['dif1'] > topdif1].index)\n",
    "    #copydf = copydf.drop(copydf[copydf['dif2'] > topdif2].index)\n",
    "    return copydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    #Informacion anterior por ticker\n",
    "    df_ticker = df2[(df2['datetime'] <  max_day_str2) & (df2['companyName']==ticker)]\n",
    "    df_ticker = df_ticker.reset_index(drop=True)\n",
    "    df_ticker['datetime'] = pd.to_datetime(df_ticker['datetime'])\n",
    "    #crear columnas de diferencia\n",
    "    df_ticker['dif1'] = df_ticker.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    df_ticker['dif2'] = df_ticker.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    df_ticker['eval'] = 1 #no se limpiara\n",
    "    #Aplha vantage descarga intraday\n",
    "    url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=' + str(ticker)+ '&interval=60min&entitlement=delayed&apikey=HR9C4MJVM7O4UUCM&datatype=csv'\n",
    "    company = pd.read_csv(url, sep=',')         \n",
    "    company = company[['close','high','low','open','volume','timestamp']]\n",
    "    company=company.rename(columns={\"open\": \"Open\",\"high\": \"High\",\"low\": \"Low\",\"close\": \"Close\",\"volume\": \"Volume\",\"timestamp\": \"datetime\"})        \n",
    "    company['companyName']=ticker\n",
    "    company['datetime'] = pd.to_datetime(company['datetime'])\n",
    "    company['datetime'] = company['datetime'].dt.tz_localize('UTC')\n",
    "    #company['datetime'] = company['datetime'].dt.tz_localize('US/Eastern')\n",
    "    company_lastday = company[company['datetime']>=max_day_str2]\n",
    "    company_lastday = company_lastday.sort_values(by=['datetime'], ascending=[True])\n",
    "    \n",
    "    #crear columnas diferencia de las colas (se evaluara el ultimo dia)\n",
    "    company_lastday['dif1'] = company_lastday.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    company_lastday['dif2'] = company_lastday.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    company_lastday['eval'] = 0 # se limpiara    \n",
    "    df_ticker = pd.concat([df_ticker, company_lastday],ignore_index=True)    \n",
    "    company_final = df_limpiar(df_ticker)    \n",
    "    df_new2 = pd.concat([df_new2, company_final],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2['High'] = np.where(df_new2['eval'] == 0, df_new2['High2'], df_new2['High'])\n",
    "df_new2['Low'] = np.where(df_new2['eval'] == 0, df_new2['Low2'], df_new2['Low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2 = df_new2.drop(columns=['dif1', 'dif2', 'eval', 'ind1', 'ind2', 'High2','Low2' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f0e91-cf20-463d-905e-7d63bfcbf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "path='data/dataxd.txt'\n",
    "folder=os.path.dirname(path)\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_new1.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion\n",
    "path='data/dataxh.txt'\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_new2.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
