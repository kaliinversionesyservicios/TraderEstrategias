{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1e400e-66ea-4231-b554-33216632364e",
   "metadata": {},
   "source": [
    "### Descarga Realtime Alpha Vantage\n",
    "###### Descarga cada 10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59056cd-968d-485d-84e7-d0777e5435ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "#from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377b8ac-a9ef-4fa4-88fc-48d9332e4a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "#leer archivo\n",
    "# Verificar si el archivo existe\n",
    "#ruta_archivo = r\"D:\\traderxpro\\data\\dataxh.txt\"\n",
    "ruta_archivo='notebooks/data/dataxh.txt'\n",
    "if os.path.exists(ruta_archivo):\n",
    "    # Cargar el archivo\n",
    "    df = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "else:\n",
    "    # Crear un DataFrame vacío\n",
    "    df = pd.DataFrame()\n",
    "    print(\"Archivo no existe. Se creó un DataFrame vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26479222-4a14-4fd1-b420-45c062542863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8db5fdef-f49d-4d6b-bfb6-4029f4bcc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_day = (df['datetime'].max()).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d12e7ea-5939-439b-9939-8a0b1b2ba4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2025, 5, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9b9a3c0-1c5a-4d78-9548-d62dbd09f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today = date.today()\n",
    "max_day_str = str(max_day)\n",
    "tickers = [\n",
    "'SPY',\n",
    "'AAPL',\n",
    "'META'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aca35012-6da3-4775-8beb-b59a5cc61ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion limpiar OUTLIERS\n",
    "def df_limpiar(df_eval):\n",
    "    #dataframe para obtener medias sin incluir fecha actual\n",
    "    df_eval2 = df_eval[df_eval['datetime']<max_day_str].tail(100)\n",
    "    \n",
    "    meandif1 = df_eval2['dif1'].mean()\n",
    "    stddif1 = df_eval2['dif1'].std()\n",
    "    topdif1 = meandif1 + stddif1 * 1.96\n",
    "\n",
    "    meandif2 = df_eval2['dif2'].mean()\n",
    "    stddif2 = df_eval2['dif2'].std()\n",
    "    topdif2 = meandif2 + stddif2 * 1.96\n",
    "    \n",
    "    #botdif = meandif - stddif * 3\n",
    "    copydf = df_eval.copy()\n",
    "    \n",
    "    #df_h.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    copydf['ind1'] = copydf.apply(lambda row: 1 if row['dif1'] > topdif1 else 0, axis=1)\n",
    "    copydf['ind2'] = copydf.apply(lambda row: 1 if row['dif2'] > topdif2 else 0, axis=1)\n",
    "\n",
    "    #hoy = datetime.now()    \n",
    "    #mes_actual = hoy.replace(day=1)\n",
    "    #mes_fin = mes_actual - relativedelta(months=3)\n",
    "    #hace_12_meses = mes_actual - relativedelta(months=12)\n",
    "    #cuartil 3\n",
    "    q3_dif1 = copydf[copydf['ind1']!=1]['dif1'].quantile(0.75)\n",
    "    q3_dif2 = copydf[copydf['ind2']!=1]['dif2'].quantile(0.75)\n",
    "    \n",
    "    #meanfin1 = copydf[(copydf['ind1']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif1'].mean()\n",
    "    #meanfin2 = copydf[(copydf['ind2']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif2'].mean()\n",
    "\n",
    "    print(\"q3_dif1:\",q3_dif1)\n",
    "    print(\"q3_dif2:\",q3_dif2)\n",
    "\n",
    "    copydf['High2']=copydf.apply(\n",
    "        lambda row: row['Close'] + q3_dif1 if (row['Close'] > row['Open']) & (row['ind1']==1) & (row['eval']==0)  else \n",
    "        row['Open'] + q3_dif1 if (row['Close'] <= row['Open']) & (row['ind1']==1) & (row['eval']==0) else\n",
    "        row['High'], axis=1)\n",
    "    copydf['Low2']=copydf.apply(\n",
    "        lambda row: row['Open'] - q3_dif2 if (row['Close'] > row['Open']) & (row['ind2']==1) & (row['eval']==0) else \n",
    "        row['Close'] - q3_dif2 if (row['Close'] <= row['Open']) & (row['ind2']==1) & (row['eval']==0) else\n",
    "        row['Low'], axis=1)\n",
    "   \n",
    "    #copydf = copydf.drop(copydf[copydf['dif1'] > topdif1].index)\n",
    "    #copydf = copydf.drop(copydf[copydf['dif2'] > topdif2].index)\n",
    "    return copydf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebde4562-23b2-472a-84c7-391d2a30220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q3_dif1: 0.537811279296875\n",
      "q3_dif2: 0.635009765625\n",
      "q3_dif1: 0.4080772399902344\n",
      "q3_dif2: 0.43499755859375\n",
      "q3_dif1: 1.2649917602538636\n",
      "q3_dif2: 1.3235321044921875\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    #Informacion anterior por ticker\n",
    "    df_ticker = df[(df['datetime'] <  max_day_str) & (df['companyName']==ticker)]\n",
    "    df_ticker = df_ticker.reset_index(drop=True)\n",
    "    df_ticker['datetime'] = pd.to_datetime(df_ticker['datetime'])\n",
    "    #crear columnas de diferencia\n",
    "    df_ticker['dif1'] = df_ticker.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    df_ticker['dif2'] = df_ticker.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    df_ticker['eval'] = 1 #no se limpiara\n",
    "    #Aplha vantage descarga intraday\n",
    "    url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=' + str(ticker)+ '&interval=60min&entitlement=delayed&apikey=HR9C4MJVM7O4UUCM&datatype=csv'\n",
    "    company = pd.read_csv(url, sep=',')         \n",
    "    company = company[['close','high','low','open','volume','timestamp']]\n",
    "    company=company.rename(columns={\"open\": \"Open\",\"high\": \"High\",\"low\": \"Low\",\"close\": \"Close\",\"volume\": \"Volume\",\"timestamp\": \"datetime\"})        \n",
    "    company['companyName']=ticker\n",
    "    company['datetime'] = pd.to_datetime(company['datetime'])\n",
    "    company['datetime'] = company['datetime'].dt.tz_localize('UTC')\n",
    "    #company['datetime'] = company['datetime'].dt.tz_localize('US/Eastern')\n",
    "    company_lastday = company[company['datetime']>=max_day_str]\n",
    "    company_lastday = company_lastday.sort_values(by=['datetime'], ascending=[True])\n",
    "    \n",
    "    #crear columnas diferencia de las colas (se evaluara el ultimo dia)\n",
    "    company_lastday['dif1'] = company_lastday.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    company_lastday['dif2'] = company_lastday.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    company_lastday['eval'] = 0 # se limpiara    \n",
    "    df_ticker = pd.concat([df_ticker, company_lastday],ignore_index=True)    \n",
    "    company_final = df_limpiar(df_ticker)    \n",
    "    df_new = pd.concat([df_new, company_final],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83a8eae4-fe7d-4ceb-82ce-8739cb03bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['High'] = np.where(df_new['eval'] == 0, df_new['High2'], df_new['High'])\n",
    "df_new['Low'] = np.where(df_new['eval'] == 0, df_new['Low2'], df_new['Low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ecb9e0b-61f9-43c3-8e7c-e92167775045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(columns=['dif1', 'dif2', 'eval', 'ind1', 'ind2', 'High2','Low2' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b74e3be-2964-48ad-b894-cd5017a28349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10489"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c47af71-79db-4f29-baa8-f66509778506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10489"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5f60393-16e1-41af-9177-ee73f842b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bokeh.plotting import figure, show, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "669baf10-e033-43d1-8446-e7aace6d5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODIGO DE REVISION CARLOS\n",
    "#dfpl = df_new.query(\"companyName=='SPY'\")\n",
    "##dfpl = df.iloc[0:1000]\n",
    "#dfpl.reset_index(drop=True, inplace=True)\n",
    "#dfpl[\"Datetime_str\"] = dfpl[\"datetime\"].astype(str)\n",
    "#\n",
    "#p = figure(width=2500, height=500,\n",
    "#        title=\"RCB\",\n",
    "#        background_fill_color=\"#efefef\",\n",
    "#        tooltips=[(\"datetime\", \"@Datetime_str\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\"), (\"ticker\",\"@companyName\")]\n",
    "#        )\n",
    "#p.xaxis.major_label_orientation = 0.8 # radians\n",
    "#p.x_range.range_padding = 0.05\n",
    "##p.xaxis.axis_line_join = \"bevel\" # radians\n",
    "#p.xaxis.axis_line_width = 2\n",
    "#\n",
    "## map dataframe indices to date strings and use as label overrides\n",
    "#p.xaxis.major_label_overrides = {\n",
    "#    #i: date.strftime('%b %d') for i, date in zip(df.index, df[\"datetime\"])\n",
    "#    i: date.strftime('%b %d %T') for i, date in zip(dfpl.index, dfpl[\"datetime\"])\n",
    "#}\n",
    "#\n",
    "#p.segment(\"index\", \"High\", \"index\",\"Low\",  color=\"black\", line_width=1, source=dfpl)\n",
    "#\n",
    "#inc = dfpl.query(\"Close>Open\")\n",
    "#dec = dfpl.query(\"Open>Close\")\n",
    "#\n",
    "#p.vbar(    \n",
    "#    x=\"index\",\n",
    "#    width=0.6,\n",
    "#    bottom=\"Open\",\n",
    "#    top=\"Close\",\n",
    "#    fill_color=\"red\",\n",
    "#    line_color=\"red\",    \n",
    "#    source=dec   \n",
    "#)\n",
    "#\n",
    "#\n",
    "#p.vbar(    \n",
    "#    x=\"index\",\n",
    "#    width=0.6,\n",
    "#    bottom=\"Open\",\n",
    "#    top=\"Close\",\n",
    "#    fill_color=\"green\",\n",
    "#    line_color=\"green\", \n",
    "#    source=inc   \n",
    "#)\n",
    "#\n",
    "##p.scatter(x=\"index\", y=\"pivotHigh\", marker=\"circle\", size=10,\n",
    "##           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista\", source=dfpl[(dfpl.isPivot==1)])\n",
    "#\n",
    "##p.scatter(x=\"index\", y=\"pivotLow\", marker=\"circle\", size=10,\n",
    "##           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista\", source=dfpl[(dfpl.isPivot==2)])\n",
    "#\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f0e91-cf20-463d-905e-7d63bfcbf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "\n",
    "#path = r'D:\\traderxpro\\data\\dataxh.txt'\n",
    "\n",
    "path='notebooks/data/dataxh.txt'\n",
    "folder=os.path.dirname(path)\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "\n",
    "\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_new.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
