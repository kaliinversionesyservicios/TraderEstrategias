{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add7e209-9b3e-4a88-9f6c-e4036fd41ac1",
   "metadata": {},
   "source": [
    "# Channel Break Out Detection Alcista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9112859-5bd6-42a9-bde4-b8ff8d2aa4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "#import matplotlib.pyplot as plt\n",
    "#import math\n",
    "from datetime import date, timedelta\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "#from bokeh.plotting import figure, show, column\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "from backtesting import Backtest, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fab280-84ca-4c2f-9784-f79dadcb26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h=pd.read_csv('data/dataxh.txt',sep='\\t')\n",
    "\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META',\n",
    "    'AAPL',\n",
    "    'AMZN',\n",
    "    'NFLX',\n",
    "    'MRNA',\n",
    "    'TSLA',\n",
    "    'TNA',\n",
    "    'GLD',\n",
    "    'SLV',\n",
    "    'USO',\n",
    "    'BAC',\n",
    "    'CVX',\n",
    "    'XOM',\n",
    "    'QQQ',\n",
    "    'MSFT',\n",
    "    'NVDA',\n",
    "    'WMT',\n",
    "    'BA',\n",
    "    'DIS',\n",
    "    'CAT',\n",
    "    'IBM',\n",
    "    'WFC',\n",
    "    'PLTR',\n",
    "    'AMD',\n",
    "    'AVGO',\n",
    "    'HOOD',\n",
    "    'CRWV',\n",
    "    'MSTR',\n",
    "    'UNH',\n",
    "    'GOOG',\n",
    "    'APP',\n",
    "    'UBER'\n",
    "]\n",
    "\n",
    "#    'SPY',\n",
    "#    'META',\n",
    "#    'AAPL',\n",
    "#    'AMZN',\n",
    "#    'NFLX',\n",
    "#    'MRNA',\n",
    "#    'TSLA',\n",
    "#    'TNA',\n",
    "#    'GLD',\n",
    "#    'SLV',\n",
    "#    'USO',\n",
    "#    'BAC',\n",
    "#    'CVX',\n",
    "#    'XOM',\n",
    "#    'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d035ad-94d3-427b-9d99-5efff5449692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h['datetime'] = pd.to_datetime(df_h['datetime'])\n",
    "df = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    company = df_h.query(\"companyName==@ticker\").copy()\n",
    "    company.sort_values(by=['datetime'])\n",
    "    #company = yf.download(ticker, start = ini2_str, end = today_str, interval='60m')\n",
    "    #company.columns = [company.columns[0][0], company.columns[1][0], company.columns[2][0], company.columns[3][0], company.columns[4][0]]\n",
    "    #company.rename(columns={'Datetime':'Gmt time'}, inplace = True)\n",
    "    #company['datetime'] = pd.to_datetime (company.index)\n",
    "    #company['companyName'] = ticker\n",
    "    company['SMA20'] = company['Close'].rolling(20).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA40'] = company['Close'].rolling(40).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA100'] = company['Close'].rolling(100).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA200'] = company['Close'].rolling(200).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    df = pd.concat([df, company],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab939271-1e70-4ea6-bc39-df024b86f50e",
   "metadata": {},
   "source": [
    "### Detect Pivots/Fractals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755f2f1c-3bb8-47b9-bf49-b89e7437100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=15\n",
    "#for ticker in tickers:\n",
    "#print(\"====\", ticker)\n",
    "#dfpl = df[(df.companyName==ticker)] #df.query(\"companyName=='AAPL'\")\n",
    "max_idx = argrelextrema(df['Close'].values, np.greater, order=ord)[0]\n",
    "min_idx = argrelextrema(df['Close'].values, np.less, order=ord)[0]\n",
    "#print(max_idx)\n",
    "#print(min_idx)\n",
    "#df['pivotHigh'] = np.nan\n",
    "#df['pivotLow'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "# Aplicar el cálculo solo a los índices en la lista\n",
    "df.loc[max_idx, 'pivotHigh'] = df['High']+1e-3\n",
    "df.loc[min_idx, 'pivotLow'] = df['Low']-(1e-3)\n",
    "df.loc[max_idx, 'isPivot'] = 1\n",
    "df.loc[min_idx, 'isPivot'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f04bb-ed9f-4732-9d38-7f8cb2869c36",
   "metadata": {},
   "source": [
    "##### Canales alcista, cuando PM40 esta por encima o cerca del precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7d94196-30b6-4e27-b8a2-97263f24b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcb01(df):\n",
    "    if ((df['isPivot']==1) & ((df['SMA40']>df['Close']) | (df['SMA40']>df['Open']) | (df['SMA20']>df['SMA40']))):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['rcb01_01'] = df.apply(rcb01, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301febb-db5f-4a68-b162-9ae2e19ec678",
   "metadata": {},
   "source": [
    "#### Detect Price Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1873740d-7344-4670-8cb0-9dea7df49305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_channel(candle, backevalTrend, trendL):\n",
    "    #localdf = df[candle-backcandles-window:candle-window]\n",
    "    localdf = dfpl.loc[candle-backevalTrend:candle] #tomar en cuenta el backcandles\n",
    "    #localdf['isPivot'] = localdf.apply(lambda x: isPivot(x.name,window), axis=1)\n",
    "    \n",
    "    #highs = localdf.High.values\n",
    "    #idxhighs = localdf.High.index\n",
    "    #lows = localdf.Low.values\n",
    "    #idxlows = localdf.Low.index\n",
    "\n",
    "    #highs = localdf.loc[localdf.index.isin(trendH)].High.values\n",
    "    #idxhighs = localdf.loc[localdf.index.isin(trendH)].High.index\n",
    "    lows = localdf.loc[localdf.index.isin(trendL)].Low.values\n",
    "    idxlows = localdf.loc[localdf.index.isin(trendL)].Low.index\n",
    "\n",
    "    #highs = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 1)].High.values\n",
    "    #idxhighs = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 1)].High.index\n",
    "    #lows = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 2)].Low.values\n",
    "    #idxlows = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 2)].Low.index\n",
    "\n",
    "    #lows = localdf.loc[localdf.index.isin(trendL)].Low.values\n",
    "    #idxlows = localdf.loc[localdf.index.isin(trendL)].Low.index\n",
    "\n",
    "    #print(\"highs:\",highs)\n",
    "    #print(\"idxhighs:\",idxhighs)\n",
    "    #print(\"lows:\",lows)\n",
    "    #print(\"idxlows:\",idxlows)\n",
    "    #print (\"tamanio:\",localdf.shape[0])\n",
    "    \n",
    "    #if len(lows)>=2 and len(highs)>=2:\n",
    "    if len(lows)>=2:\n",
    "        sl_lows, interc_lows, r_value_l, _, _ = stats.linregress(idxlows,lows)\n",
    "        #sl_highs, interc_highs, r_value_h, _, _ = stats.linregress(idxhighs,highs)    \n",
    "        #return(sl_lows, interc_lows, sl_highs, interc_highs, r_value_l**2, r_value_h**2)\n",
    "        return(sl_lows, interc_lows, r_value_l**2)\n",
    "    else:\n",
    "        return(0,0,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea43d11-bb56-4a09-8d54-0bfd0dfc987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backcandle(candle):\n",
    "    \n",
    "    trendH = []\n",
    "    backeval = 0\n",
    "    val = 0\n",
    "\n",
    "    #print(\"candle:\", candle)\n",
    "    dfpl['PM20_PM40'] = dfpl['SMA20']-dfpl['SMA40']\n",
    "    idinicial = dfpl.index[0]\n",
    "    velas = candle - idinicial\n",
    "\n",
    "    #print(\"idinicial:\", idinicial)\n",
    "    if (dfpl.loc[candle,\"PM20_PM40\"]>0):\n",
    "        idx_negativo = dfpl.loc[:candle, 'PM20_PM40'][::-1].lt(0).idxmax()\n",
    "        if (idx_negativo==candle):\n",
    "            backeval = candle - velas\n",
    "            \n",
    "        else:\n",
    "            backeval = idx_negativo - 4\n",
    "        \n",
    "    val = candle - backeval\n",
    "    \n",
    "    #print(\"backeval1:\",backeval)\n",
    "    \n",
    "    if val>velas:\n",
    "        backeval=candle-velas\n",
    "\n",
    "    #print(\"backeval2:\",backeval)\n",
    "    if ((dfpl.loc[backeval,\"PM20_PM40\"]>0) & (val<velas)):\n",
    "        idx_negativo = dfpl.loc[:backeval, 'PM20_PM40'][::-1].lt(0).idxmax()\n",
    "        backeval = idx_negativo - 4\n",
    "    #print(\"backeval3:\",backeval)\n",
    "\n",
    "    val = candle - backeval\n",
    "    if val>velas:\n",
    "        backeval=candle-velas\n",
    "        \n",
    "    #print(\"backeval4:\",backeval)\n",
    "    #ini = candle - backeval\n",
    "    ini = backeval\n",
    "    trendprev=dfpl.loc[ini:candle]\n",
    "    trend = trendprev.reset_index(drop=False)\n",
    "\n",
    "    idxlows = trend.index.to_numpy().reshape(-1,1) # Convertir X a una matriz 2D\n",
    "    lows = trend.Low.values\n",
    "    modelo1 = LinearRegression()\n",
    "    modelo1.fit(idxlows, lows)\n",
    "    # Obtener la predicción de la línea de regresión\n",
    "    Y_pred = modelo1.predict(idxlows)\n",
    "    # Calcular la distancia solo de los puntos que están POR ENCIMA de la línea\n",
    "    trend['Distancia'] = Y_pred - trend[\"Low\"]  # Diferencia entre el valor real y la predicción\n",
    "    # Filtrar los puntos que están por debajo (donde Y > Y_pred, es decir, Distancia > 0)\n",
    "    df_encima = trend[trend['Distancia'] > 0]\n",
    "    puntos_mas_lejanos = df_encima.nlargest(2, 'Distancia')   #2 puntos mas lejanos\n",
    "    trendL = puntos_mas_lejanos[\"index\"].tolist()\n",
    "    trendL.append(candle)   \n",
    "    \n",
    "    return trendL, backeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746c605-eeaf-4691-b332-3c5afe45243a",
   "metadata": {},
   "source": [
    "### Detect Break Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eb0e6d2-7707-4624-bee3-0465d77901ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendChannel(row,candle, backeval, window, sl_highs, interc_lows):\n",
    "\n",
    "    if (candle-backeval-window)<0:\n",
    "        return np.nan\n",
    "\n",
    "    #print(\"=== DATOS ===\")\n",
    "    #print(\"candle:\",candle)\n",
    "    #print(\"backcandles:\",backcandles)\n",
    "    #print(\"window:\",window)\n",
    "    #trendprevlow = (sl_lows*row['id'].shift(1).fillna(0) + interc_lows)\n",
    "    #trendprevhigh = (sl_highs*row['id'].shift(1).fillna(0) + interc_highs)\n",
    "    ini=candle-backeval\n",
    "    fin=candle+window\n",
    "    #x = np.array(range(candle-backcandles-window, candle+window))\n",
    "    trendcurrlow = np.where(np.logical_or((row.index > fin),  (row.index <  ini)), np.nan, (sl_lows*row.index + interc_lows))\n",
    "    #trendcurrhigh = (sl_highs*row['id'] + interc_highs)\n",
    "    \n",
    "    #print(\"candle:\",candle,\",backeval\", backeval, \", ini:\", ini, \", fin:\", fin,   \", rowMin:\", row.index[0],\", rowMax:\", row.index[-1])\n",
    "    #trendcurrhigh = np.where(np.logical_or((row.index > fin),  (row.index <  ini)), np.nan, (sl_highs*row.index + interc_highs))\n",
    "    return trendcurrlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e480264-0fde-4a97-af4e-a86b58a4b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBreakOut(candleEval,backcandles, window, start, candle):\n",
    "    if (candleEval-backcandles-window)<0:\n",
    "        return 0\n",
    "\n",
    "    if candleEval==start:\n",
    "        prev_idx = candleEval\n",
    "    else:\n",
    "        prev_idx = candleEval-1\n",
    "        \n",
    "    prev_high = dfpl.loc[prev_idx].High\n",
    "    prev_low = dfpl.loc[prev_idx].Low\n",
    "    prev_close = dfpl.loc[prev_idx].Close\n",
    "    \n",
    "    curr_idx = candleEval\n",
    "    curr_high = dfpl.loc[candleEval].High\n",
    "    curr_low = dfpl.loc[candleEval].Low\n",
    "    curr_close = dfpl.loc[candleEval].Close\n",
    "    curr_open = dfpl.loc[candleEval].Open\n",
    "\n",
    "    trend_prevlow=dfpl.loc[prev_idx].trendcurrlow\n",
    "    #trend_prevhigh=dfpl.loc[prev_idx].trendcurrhigh\n",
    "\n",
    "    trend_currlow=dfpl.loc[candleEval].trendcurrlow\n",
    "    #trend_currhigh=dfpl.loc[candleEval].trendcurrhigh\n",
    "\n",
    "    #codigo para tendencia LOW, nos importa breaks en tendencia HIGH\n",
    "    if ( prev_high > trend_prevlow and\n",
    "        prev_close < trend_prevlow and\n",
    "        curr_open < trend_currlow and\n",
    "        curr_close < trend_currlow and \n",
    "        candleEval>candle): #and r_sq_l > 0.9\n",
    "        return 1\n",
    "    \n",
    "   # #if ( prev_low < trend_prevhigh and\n",
    "   #     prev_close > trend_prevhigh and\n",
    "   #     curr_open > trend_currhigh and\n",
    "   #     curr_close > trend_currhigh and\n",
    "   #     candleEval>candle): #and r_sq_h > 0.9\n",
    "   #     return 2\n",
    "\n",
    "   # elif (curr_open > trend_currhigh and\n",
    "   #     curr_close > trend_currhigh and candleEval>candle):\n",
    "   #     return 3\n",
    "    \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04c0d310-0135-4029-83d4-834b5b402c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakpointpos(x):\n",
    "    if x['isBreakOutIni'] in (2,3):\n",
    "        return x['Low']+3e-3\n",
    "    elif x['isBreakOutIni']==1:\n",
    "        return x['High']-3e-3\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfc3a9-1c1a-4615-88b4-fe7061f871b4",
   "metadata": {},
   "source": [
    "###### Hallando casos de Ruptura del Canal Alcista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80471e6b-41e2-424d-962d-72757b94aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revisionVelas(dfpl, backeval,window, candle):\n",
    "    #Revision de Velas\n",
    "    #Promedio del volumen de 50 velas antes del posible caso\n",
    "    promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "    #puede darse cualquiera de estas condiciones: \n",
    "    # - que la vela sea verde, que tenga volumen, este por encima de la linea trend y que tenga cuerpo (cierra por encima de su tercera parte)\n",
    "    # - que la vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "    j=candle+1\n",
    "    k=candle+window\n",
    "    ind_vela=0\n",
    "    \n",
    "    #k no puede pasrse del rango\n",
    "    maxindex = dfpl.index[-1]\n",
    "    if (k>maxindex):\n",
    "        k=maxindex\n",
    "    \n",
    "    #print(\"candle:\",candle)\n",
    "    #print(\"window:\",window)\n",
    "    #print(\"j:\",j, \",k:\",k)\n",
    "    \n",
    "    #Evaluacion de velas ALCISTAS\n",
    "    dfpl[\"cdlengulfing\"] = ta.CDLENGULFING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlhammer\"] = ta.CDLHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmorningstar\"] = ta.CDLMORNINGSTAR(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlpiercing\"] = ta.CDLPIERCING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlclosingmarubozu\"] = ta.CDLCLOSINGMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmarubozu\"] = ta.CDLMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdl3whitesoldiers\"] = ta.CDL3WHITESOLDIERS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharami\"] = ta.CDLHARAMI(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharamicross\"] = ta.CDLHARAMICROSS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlinvertdhammer\"] = ta.CDLINVERTEDHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlladderbottom\"] = ta.CDLLADDERBOTTOM(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "\n",
    "    dfpl['Vela_Roja'] = dfpl['Close'] < dfpl['Open']\n",
    "    # Calcular el nivel de la tercera parte\n",
    "    #dfpl['Third_Level'] = dfpl['Low'] + (dfpl['High'] - dfpl['Low']) / 3\n",
    "    dfpl['Third_Level'] = dfpl['Open'] + (dfpl['High'] - dfpl['Low']) / 3\n",
    "    # Verificar si la vela cierra por encima de su tercera parte, vela con cuerpo\n",
    "    dfpl['Above_Third'] = dfpl['Close'] > dfpl['Third_Level']\n",
    "\n",
    "    while j<=k:            \n",
    "        \n",
    "        vol = dfpl.loc[j,\"Volume\"]\n",
    "        above_Third = dfpl.loc[j,\"Above_Third\"]\n",
    "        vela_Roja = dfpl.loc[j,\"Vela_Roja\"]\n",
    "        lineTrend = dfpl.loc[j,'trendcurrlow']\n",
    "        high = dfpl.loc[j,'High']\n",
    "        close = dfpl.loc[j,'Close']\n",
    "\n",
    "        cdlengulfing = dfpl.loc[j,\"cdlengulfing\"]\n",
    "        cdlhammer = dfpl.loc[j,\"cdlhammer\"]\n",
    "        cdlmorningstar = dfpl.loc[j,\"cdlmorningstar\"]\n",
    "        cdlpiercing = dfpl.loc[j,\"cdlpiercing\"]\n",
    "        cdlclosingmarubozu = dfpl.loc[j,\"cdlclosingmarubozu\"]\n",
    "        cdlmarubozu = dfpl.loc[j,\"cdlmarubozu\"]\n",
    "        cdl3whitesoldiers = dfpl.loc[j,\"cdl3whitesoldiers\"]\n",
    "        cdlharami = dfpl.loc[j,\"cdlharami\"]\n",
    "        cdlharamicross = dfpl.loc[j,\"cdlharamicross\"]\n",
    "        cdlinvertdhammer = dfpl.loc[j,\"cdlinvertdhammer\"]\n",
    "        cdlladderbottom = dfpl.loc[j,\"cdlladderbottom\"]\n",
    "\n",
    "        #vela consecutiva alcista\n",
    "        candle_up = (#dfpl.loc[j,\"Vela_Verde\"]==True \n",
    "                     #and dfpl.loc[j-1,\"Vela_Verde\"]==True \n",
    "                     dfpl.loc[j,\"High\"]> dfpl.loc[j-1,\"High\"]\n",
    "                     and dfpl.loc[j-1,\"High\"]> dfpl.loc[j,\"Low\"]\n",
    "                     and dfpl.loc[j,\"Low\"]> dfpl.loc[j-2,\"High\"]\n",
    "                     and dfpl.loc[j-2,\"High\"]> dfpl.loc[j-1,\"Low\"]\n",
    "                     and dfpl.loc[j-1,\"Low\"]> dfpl.loc[j-3,\"High\"]\n",
    "                     and dfpl.loc[j-3,\"High\"]> dfpl.loc[j-2,\"Low\"]\n",
    "                     and dfpl.loc[j-2,\"Low\"]> dfpl.loc[j-3,\"Low\"]\n",
    "                     #and dfpl.loc[j,\"Close\"]> dfpl.loc[j-1,\"High\"] \n",
    "                     #and dfpl.loc[j-1,\"Close\"]>dfpl.loc[j-2,\"High\"]\n",
    "                     #and dfpl.loc[j-1,\"Close\"]>dfpl.loc[j-3,\"High\"] \n",
    "                    )\n",
    "\n",
    "        if (candle_up==True and close>lineTrend):\n",
    "            ind_vela=ind_vela+1\n",
    "        #vela sea verde, que tenga volumen, que tenga cuerpo y que este por encima de la linea trend\n",
    "        #if (vela_Verde==True and promVol<=vol and above_Third==True and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1\n",
    "        \n",
    "        #vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "        #if (\n",
    "        #    (cdlhammer>0 or\n",
    "        #     cdlmorningstar>0 or\n",
    "        #     cdlpiercing>0 or\n",
    "        #     cdl3whitesoldiers>0 or\n",
    "        #     cdlharami>0 or\n",
    "        #     cdlharamicross>0 or\n",
    "        #     cdlinvertdhammer>0 or\n",
    "        #     cdlladderbottom>0\n",
    "        #    )\n",
    "        #    and promVol<=vol\n",
    "        #    and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1\n",
    "\n",
    "        #vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "        #if (\n",
    "        #    (cdlclosingmarubozu>0 or\n",
    "        #     cdlmarubozu>0 or\n",
    "        #     cdlengulfing>0 or\n",
    "        #     cdlhammer>0\n",
    "        #    )\n",
    "        #    #and promVol<=vol\n",
    "        #    and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1 \n",
    "            \n",
    "        j=j+1\n",
    "    \n",
    "    return 1 #1 para mostrar todo ind_vela para que funcione el filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d994f943-5fc5-43c7-9604-84976d99a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===posible caso: 75 SPY\n",
      "===posible caso: 144 SPY\n",
      "===posible caso: 220 SPY\n",
      "h1\n",
      "220 SPY\n",
      "===posible caso: 264 SPY\n",
      "h1\n",
      "264 SPY\n",
      "===posible caso: 282 SPY\n",
      "h2\n",
      "h4\n",
      "h1\n",
      "282 SPY\n",
      "===posible caso: 306 SPY\n",
      "===posible caso: 332 SPY\n",
      "===posible caso: 352 SPY\n",
      "===posible caso: 444 SPY\n",
      "h1\n",
      "444 SPY\n",
      "===posible caso: 506 SPY\n",
      "===posible caso: 642 SPY\n",
      "h1\n",
      "642 SPY\n",
      "===posible caso: 809 SPY\n",
      "===posible caso: 886 SPY\n",
      "===posible caso: 946 SPY\n",
      "===posible caso: 975 SPY\n",
      "h1\n",
      "975 SPY\n",
      "===posible caso: 1011 SPY\n",
      "h1\n",
      "1011 SPY\n",
      "===posible caso: 1081 SPY\n",
      "===posible caso: 1159 SPY\n",
      "h1\n",
      "1159 SPY\n",
      "===posible caso: 1219 SPY\n",
      "h1\n",
      "1219 SPY\n",
      "===posible caso: 1249 SPY\n",
      "===posible caso: 1273 SPY\n",
      "===posible caso: 1320 SPY\n",
      "h1\n",
      "1320 SPY\n",
      "===posible caso: 1343 SPY\n",
      "h1\n",
      "1343 SPY\n",
      "===posible caso: 1367 SPY\n",
      "===posible caso: 1408 SPY\n",
      "===posible caso: 1591 SPY\n",
      "h1\n",
      "1591 SPY\n",
      "===posible caso: 1694 SPY\n",
      "h1\n",
      "1694 SPY\n",
      "===posible caso: 1805 SPY\n",
      "h1\n",
      "1805 SPY\n",
      "===posible caso: 1840 SPY\n",
      "===posible caso: 1882 SPY\n",
      "===posible caso: 1961 SPY\n",
      "===posible caso: 1991 SPY\n",
      "===posible caso: 2014 SPY\n",
      "===posible caso: 2151 SPY\n",
      "===posible caso: 2281 SPY\n",
      "h1\n",
      "2281 SPY\n",
      "===posible caso: 2332 SPY\n",
      "===posible caso: 2401 SPY\n",
      "h1\n",
      "2401 SPY\n",
      "===posible caso: 2428 SPY\n",
      "h1\n",
      "2428 SPY\n",
      "===posible caso: 2459 SPY\n",
      "===posible caso: 2481 SPY\n",
      "===posible caso: 2533 SPY\n",
      "h1\n",
      "2533 SPY\n",
      "===posible caso: 2658 SPY\n",
      "h1\n",
      "2658 SPY\n",
      "===posible caso: 2703 SPY\n",
      "===posible caso: 2750 SPY\n",
      "===posible caso: 2872 SPY\n",
      "h1\n",
      "2872 SPY\n",
      "===posible caso: 2908 SPY\n",
      "===posible caso: 2940 SPY\n",
      "===posible caso: 2996 SPY\n",
      "===posible caso: 3121 SPY\n",
      "===posible caso: 3158 SPY\n",
      "===posible caso: 3352 SPY\n",
      "===posible caso: 3427 SPY\n",
      "h1\n",
      "3427 SPY\n",
      "===posible caso: 3483 SPY\n",
      "===posible caso: 3560 SPY\n",
      "h3\n",
      "h4\n",
      "h3\n",
      "h4\n",
      "h3\n",
      "h4\n",
      "h3\n",
      "h4\n",
      "3560 SPY\n",
      "===posible caso: 3644 META\n",
      "===posible caso: 3688 META\n",
      "===posible caso: 3715 META\n",
      "===posible caso: 3760 META\n",
      "===posible caso: 3786 META\n",
      "===posible caso: 3840 META\n",
      "===posible caso: 3882 META\n",
      "h1\n",
      "3882 META\n",
      "===posible caso: 3917 META\n",
      "===posible caso: 4002 META\n",
      "===posible caso: 4049 META\n",
      "h1\n",
      "4049 META\n",
      "===posible caso: 4071 META\n",
      "h1\n",
      "4071 META\n",
      "===posible caso: 4142 META\n",
      "===posible caso: 4207 META\n",
      "h1\n",
      "4207 META\n",
      "===posible caso: 4232 META\n",
      "h1\n",
      "4232 META\n",
      "===posible caso: 4261 META\n",
      "===posible caso: 4371 META\n",
      "===posible caso: 4411 META\n",
      "===posible caso: 4575 META\n",
      "h1\n",
      "4575 META\n",
      "===posible caso: 4643 META\n",
      "===posible caso: 4719 META\n",
      "===posible caso: 4742 META\n",
      "h1\n",
      "4742 META\n",
      "===posible caso: 4783 META\n",
      "h1\n",
      "4783 META\n",
      "===posible caso: 4806 META\n",
      "===posible caso: 4882 META\n",
      "h1\n",
      "4882 META\n",
      "===posible caso: 4908 META\n",
      "h1\n",
      "4908 META\n",
      "===posible caso: 4973 META\n",
      "===posible caso: 5043 META\n",
      "===posible caso: 5105 META\n",
      "h1\n",
      "5105 META\n",
      "===posible caso: 5222 META\n",
      "===posible caso: 5299 META\n",
      "h1\n",
      "5299 META\n",
      "===posible caso: 5342 META\n",
      "===posible caso: 5373 META\n",
      "h1\n",
      "5373 META\n",
      "===posible caso: 5395 META\n",
      "h1\n",
      "5395 META\n",
      "===posible caso: 5440 META\n",
      "===posible caso: 5477 META\n",
      "===posible caso: 5496 META\n",
      "h1\n",
      "5496 META\n",
      "===posible caso: 5556 META\n",
      "===posible caso: 5604 META\n",
      "===posible caso: 5676 META\n",
      "h1\n",
      "5676 META\n",
      "===posible caso: 5746 META\n",
      "h1\n",
      "5746 META\n",
      "===posible caso: 5874 META\n",
      "h2\n",
      "h4\n",
      "h2\n",
      "h4\n",
      "h1\n",
      "5874 META\n",
      "===posible caso: 5926 META\n",
      "===posible caso: 6047 META\n",
      "===posible caso: 6092 META\n",
      "===posible caso: 6226 META\n",
      "h1\n",
      "6226 META\n",
      "===posible caso: 6246 META\n",
      "===posible caso: 6308 META\n",
      "===posible caso: 6358 META\n",
      "===posible caso: 6376 META\n",
      "===posible caso: 6464 META\n",
      "===posible caso: 6509 META\n",
      "h1\n",
      "6509 META\n",
      "===posible caso: 6546 META\n",
      "h1\n",
      "6546 META\n",
      "===posible caso: 6592 META\n",
      "===posible caso: 6724 META\n",
      "===posible caso: 6768 META\n",
      "===posible caso: 6916 META\n",
      "h1\n",
      "6916 META\n",
      "===posible caso: 6962 META\n",
      "===posible caso: 7004 META\n",
      "===posible caso: 7047 META\n",
      "===posible caso: 7091 META\n",
      "===posible caso: 7122 META\n"
     ]
    }
   ],
   "source": [
    "df_casos = pd.DataFrame()\n",
    "caso = 0\n",
    "ticker2 = \"\"\n",
    "window=5\n",
    "backeval=75\n",
    "backevalTrend=0\n",
    "dfpl = pd.DataFrame\n",
    "trendH = []\n",
    "trendL = []\n",
    "cant = 0\n",
    "for i, row in df.iterrows():\n",
    "    #if (i==3560):\n",
    "    if(df['rcb01_01'][i]==1): #posibles casos \n",
    "        print(\"===posible caso:\",i, df['companyName'][i])\n",
    "        cant = 0\n",
    "        candle = i\n",
    "        cnt = 0\n",
    "        #valiniHigh = df.loc[candle,\"High\"]\n",
    "        #valiniLow = df.loc[candle,\"Low\"]\n",
    "        ticker = df['companyName'][i]\n",
    "        #Reinicio de casos por company\n",
    "        if ticker2 != ticker:\n",
    "            ticker2 = ticker\n",
    "            caso = 0\n",
    "        dfpl = df[(df.companyName==ticker)].loc[i-backeval:i+backeval]       \n",
    "\n",
    "        #print(\"rowMin:\", dfpl.index[0],\", rowMax:\", dfpl.index[-1])\n",
    "                    \n",
    "        h=1\n",
    "        l=1\n",
    "\n",
    "        cant = cant +1\n",
    "        cantHorasTrend=0\n",
    "        #print(\"opcionH:\",h,\"opcionL:\",l)\n",
    "        trendL, backevalTrend = backcandle(candle)\n",
    "        #print (\"-->trendH:\",trendH)\n",
    "        #print (\"-->backevalTrend:\",backevalTrend)    \n",
    "        \n",
    "        cantHorasTrend = (dfpl.loc[candle,\"datetime\"] - dfpl.loc[backevalTrend,\"datetime\"]).total_seconds() / 3600\n",
    "\n",
    "        if (cantHorasTrend>48): #Verificacion de caida por lo menos 2 dias\n",
    "            backevalTrend2 = candle - backevalTrend\n",
    "            #print (\"backevalTrend2\", backevalTrend2)\n",
    "                        \n",
    "            #revision de trend negativo indica que esta cayendo, solo me quedo con estos casos\n",
    "            sl_lows, interc_lows, r_sq_l = collect_channel(candle, backevalTrend2, trendL)\n",
    "                    \n",
    "    \n",
    "            #print(\"======:\", candle)\n",
    "            #print(\"===trendH===\")\n",
    "            #print(trendH)\n",
    "            #print(\"===trendL===\")\n",
    "            #print(trendL)\n",
    "            dfpl.loc[trendL, \"trendL\"] = 1\n",
    "                                \n",
    "            #print(\"sl_lows:\", sl_lows, \", interc_lows:\", interc_lows, \", r_sq_l:\", r_sq_l)\n",
    "            if (sl_lows>=0): #solo tendencias a la alza and ind_vela>0 sl_lows<0 and r_sq_h>=0.7  and sl_highs<=-0.1 and ind_vela>0\n",
    "                \n",
    "                #crear linea de tendencia high y low\n",
    "                dfpl['trendcurrlow']  = trendChannel(dfpl,candle,backevalTrend2,window,sl_lows,interc_lows)\n",
    "                \n",
    "                ind_vela = revisionVelas(dfpl, backeval,window, candle)\n",
    "                promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "    \n",
    "                #print(\"ind_vela:\",ind_vela)\n",
    "                if (ind_vela>0):\n",
    "                    dfpl[\"bearishSlope\"] = np.nan #pendiente bajista en vacio\n",
    "                    dfpl.loc[i, \"bearishSlope\"] = 1 #pendiente bajista solo al punto evaluado            \n",
    "                    dfpl[\"ind_posicion\"] = 0\n",
    "                    dfpl.loc[(dfpl.index < i), 'ind_posicion'] = -1\n",
    "                    dfpl.loc[(dfpl.index > i), 'ind_posicion'] = 1\n",
    "                    dfpl[\"promVol\"] = promVol\n",
    "                    dfpl[\"sl_lows\"] = sl_lows\n",
    "                    dfpl[\"r_sq_l\"] = r_sq_l\n",
    "            \n",
    "                    start = dfpl.index[0]\n",
    "                    dfpl[\"isBreakOut\"] = [isBreakOut(candleEval, backevalTrend2, window, start, candle) for candleEval in dfpl.index]\n",
    "                    # Solo me quedo con el primer BREAK OUT\n",
    "                    cnt = dfpl.query(\"isBreakOut==1 and Close<Open\").shape[0] \n",
    "                    id=0\n",
    "                    id2=0\n",
    "                    if cnt>0:\n",
    "                        id = dfpl.query(\"isBreakOut==1 and Close<Open\").index[0]                        \n",
    "                        #dfpl['isBreakOutIni'] = np.where(id!=dfpl.index, np.nan, dfpl['isBreakOut'])                        \n",
    "                        dfpl.loc[id,'isBreakOutIni'] = 1\n",
    "\n",
    "                        k=0\n",
    "                        while (k<=3):\n",
    "                            dfpl['breakpointpos'] = dfpl.apply(lambda row: breakpointpos(row), axis=1)\n",
    "                            cnt2 = dfpl.query(\"index>@id and isPivot==2\").shape[0]\n",
    "                            \n",
    "                            if cnt2>0:\n",
    "                                id2 = dfpl.query(\"index>@id and isPivot==2\").index[0]\n",
    "                                dfpl.loc[id2,'isBreakOutFinal'] = 1\n",
    "                                k=4\n",
    "                                print(\"h1\")\n",
    "                            else:\n",
    "                                #revisar 25 velas mas\n",
    "                                #print(\"paso8\")\n",
    "                                idfinal = dfpl.index[-1] \n",
    "                                idfinal2 = idfinal+25\n",
    "                                if idfinal2 in df[df['companyName']==ticker].index:\n",
    "                                    dfpl2 = df[(df.companyName==ticker)].loc[idfinal+1:idfinal2].copy()\n",
    "                                    dfpl = pd.concat([dfpl, dfpl2],ignore_index=False)    \n",
    "                                    print(\"h2\")\n",
    "                                else:                  \n",
    "                                    dfpl['isBreakOutFinal'] = np.nan\n",
    "                                    print(\"h3\")\n",
    "\n",
    "                                k=k+1\n",
    "                                print(\"h4\")\n",
    "                                \n",
    "                        \n",
    "                    else:\n",
    "                        dfpl['isBreakOutIni'] = np.nan                  \n",
    "                        dfpl['breakpointpos'] = np.nan\n",
    "            \n",
    "                    if cnt>0:\n",
    "                        #INSERT CASO\n",
    "                        caso=caso+1                            \n",
    "                        dfpl[\"caso\"] = caso\n",
    "                        print(i, df['companyName'][i])\n",
    "                        if len(df_casos)<1:\n",
    "                            df_casos = dfpl\n",
    "                        else:\n",
    "                            df_casos = pd.concat([df_casos, dfpl],ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cbb39-d190-488e-9acb-32cb2094acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "#path = r'C:\\Users\\carlo\\OneDrive\\Documentos\\TRADER\\traderapp\\data\\rcb_h.txt'\n",
    "path='data/rca_h.txt'\n",
    "\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_casos.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b1b22-7ae9-4f2e-b42e-a9064f2cbf09",
   "metadata": {},
   "source": [
    "### BACKTESTING\n",
    "### Usando paquete backtesting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb317fbb-f021-461f-a8c0-40463b42ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos2 = df_casos.query(\"isBreakOutIni==1 or isBreakOutFinal==1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8ad35c1-1c5e-438c-9fd9-20bf3feeee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== BACKTESTING ================= #\n",
    "# obteniendo dataframe backtesting\n",
    "df_backTesting = pd.merge(df, df_casos2[['datetime','companyName', 'isBreakOutIni','isBreakOutFinal','caso']], on = ['companyName','datetime'], how='left')\n",
    "# datos de trade se asigna una vela anterior debido a que backtesting.py toma entra como la siguiente vela\n",
    "df_backTesting['isBreakOutIni'] = df_backTesting['isBreakOutIni'].shift(-1)\n",
    "df_backTesting['isBreakOutFinal'] = df_backTesting['isBreakOutFinal'].shift(-1)\n",
    "#modificamos indice con el compo datetime\n",
    "df_backTesting.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cce1a-a09b-471c-a83c-3ba51e7a8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategia\n",
    "class strategyRupturaCanal(Strategy):    \n",
    "    def init(self):        \n",
    "        self.breakout_entry = self.I(lambda x: x, self.data.isBreakOutIni) #Indica la señal entrada al backtesting\n",
    "        self.breakout_exit = self.I(lambda x: x, self.data.isBreakOutFinal) #Indica la señal salida al backtesting\n",
    "\n",
    "    def next(self):       \n",
    "        #print(self.data)        \n",
    "        if self.breakout_entry[-1] == 1:\n",
    "            self.sell()  #COMPRA\n",
    "        elif self.breakout_exit[-1] == 1 and self.position:\n",
    "            self.position.close() #CIERRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd5f99-505d-4813-ad34-fb872cc5def8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3333 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para SPY:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_32092\\3615098657.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3189 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\backtesting\\backtesting.py:954: UserWarning: time=508: Broker canceled the relative-sized order due to insufficient margin.\n",
      "  warnings.warn(\n",
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\backtesting\\backtesting.py:954: UserWarning: time=1834: Broker canceled the relative-sized order due to insufficient margin.\n",
      "  warnings.warn(\n",
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\backtesting\\backtesting.py:954: UserWarning: time=2985: Broker canceled the relative-sized order due to insufficient margin.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para META:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_32092\\3615098657.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    }
   ],
   "source": [
    "# Por cada TIcket\n",
    "my_stats = {}\n",
    "estadisticas = pd.DataFrame()          # lista para ticker\n",
    "tradesprev = pd.DataFrame()     # lista para cada caso por ticker\n",
    "for ticker in df_backTesting['companyName'].unique():\n",
    "    ticker_data = df_backTesting[df_backTesting['companyName'] == ticker].copy() #Filtro por cada ticker\n",
    "    bt = Backtest(ticker_data, strategyRupturaCanal, cash=10_000)\n",
    "    my_stats = bt.run()\n",
    "    listTrades = my_stats['_trades']\n",
    "    tradesdf = pd.DataFrame(listTrades) #trades\n",
    "    tradesdf['Ticker'] = ticker\n",
    "    stats_filter={\n",
    "        'Ticker':ticker,\n",
    "        'EntryTime':my_stats['Start'],\n",
    "        'ExitTime':my_stats['End'],\n",
    "        'Return [%]': my_stats['Return [%]'],\n",
    "        'CAGR [%]': my_stats['Return (Ann.) [%]'],\n",
    "        'Sharpe Ratio': my_stats['Sharpe Ratio'],\n",
    "        'Max. Drawdown [%]': my_stats['Max. Drawdown [%]'],\n",
    "        'Win Rate [%]': my_stats['Win Rate [%]'],\n",
    "        '# Trades': my_stats['# Trades'],\n",
    "        'Expectancy [%]': my_stats['Expectancy [%]'],\n",
    "        'Profit Factor': my_stats['Profit Factor'],\n",
    "        'Duration': my_stats['Duration'],\n",
    "        'Avg. Trade [%]':my_stats['Avg. Trade [%]'],\n",
    "        'Max. Trade Duration':my_stats['Max. Trade Duration'],\n",
    "        'Avg. Trade Duration':my_stats['Avg. Trade Duration']\n",
    "    }\n",
    "    stat=pd.DataFrame([stats_filter])\n",
    "    if tradesprev.shape[0]==0:\n",
    "        tradesprev = tradesdf.copy()\n",
    "        estadisticas=stat.copy()\n",
    "    else:\n",
    "        tradesprev = pd.concat([tradesprev, tradesdf],ignore_index=True)\n",
    "        estadisticas=pd.concat([estadisticas, stat],ignore_index=True)\n",
    "    # Mostramos\n",
    "    #bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdac24e-07d0-4923-b11b-c35831321046",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = df_casos2[(df_casos2['isBreakOutIni']==1)].copy()\n",
    "df_casos3_ini=ini.rename(columns={'Open': 'EntryPrice', 'datetime': 'EntryTime', 'companyName': 'Ticker'})[['EntryPrice','Ticker','caso','EntryTime']]\n",
    "final = df_casos2[(df_casos2['isBreakOutFinal']==1)].copy()\n",
    "df_casos3_final=final.rename(columns={'Open': 'ExitPrice', 'datetime': 'ExitTime', 'companyName': 'Ticker'})[['ExitPrice','Ticker','caso','ExitTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos3=df_casos3_ini.merge(df_casos3_final,on=['Ticker','caso'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0668a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.merge(df_casos3, tradesprev, on = ['EntryTime','Ticker'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitPrice(x):\n",
    "    if pd.isna(x['ExitPrice_x']):\n",
    "        return x['ExitPrice_y']\n",
    "    else:\n",
    "        return x['ExitPrice_x']\n",
    "trades['ExitPrice'] = trades.apply(lambda row: exitPrice(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.rename(columns={'EntryPrice_x': 'EntryPrice'})\n",
    "trades = trades.drop(['EntryPrice_y','ExitPrice_x', 'ExitPrice_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitTime(x):\n",
    "    if pd.isna(x['ExitTime_x']):\n",
    "        return x['ExitTime_y']\n",
    "    else:\n",
    "        return x['ExitTime_x']\n",
    "trades['ExitTime'] = trades.apply(lambda row: exitTime(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193cdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(x):\n",
    "    if pd.isna(x['Duration']):\n",
    "        if pd.isna(x['ExitTime']):\n",
    "            return pd.NaT\n",
    "        else:\n",
    "            return x['ExitTime']-x['EntryTime']\n",
    "    else:\n",
    "        return x['Duration']\n",
    "trades['Duration'] = trades.apply(lambda row: duration(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.drop(['ExitTime_x', 'ExitTime_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ca541",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades=trades[['Ticker','EntryTime','ExitTime','EntryPrice','ExitPrice','Duration','Size','EntryBar','ExitBar','ReturnPct','PnL','caso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in estadisticas['Ticker'].unique():\n",
    "    count = trades[trades[\"Ticker\"] == item].shape[0]\n",
    "    estadisticas.loc[estadisticas['Ticker'] == item, '# Trades'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORTACION DE DATAFRAME\n",
    "path = 'data/backtesting'\n",
    "\n",
    "# Asegurarse de que el directorio existe\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "path_trades = os.path.join(path, 'trades_rca.txt')\n",
    "path_estadisticas = os.path.join(path, 'estadisticas_rca.txt')\n",
    "\n",
    "for file_path in [path_trades, path_estadisticas]:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"File does not exist: {file_path}. It will be created.\")\n",
    "\n",
    "trades.to_csv(path_trades, header=True, index=False, sep='\\t', mode='w')\n",
    "estadisticas.to_csv(path_estadisticas, header=True, index=False, sep='\\t', mode='w')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
