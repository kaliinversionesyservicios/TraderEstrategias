{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b70f4b-a8b2-4a6a-958a-5dcd1cd8e77c",
   "metadata": {},
   "source": [
    "### PISO FUERTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d35c1-2cc9-4aa8-80c7-eb3b83120eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "#import matplotlib.pyplot as plt\n",
    "#import math\n",
    "from datetime import date, timedelta\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "from bokeh.plotting import figure, show, column\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "from backtesting import Backtest, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046199b-ac4b-417e-945e-dc76d7dfda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.read_csv('data/dataxd.txt', sep=\"\\t\")\n",
    "df_h=pd.read_csv('data/dataxh.txt',sep='\\t')\n",
    "\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META',\n",
    "    'AAPL',\n",
    "    'AMZN',\n",
    "    'NFLX',\n",
    "    'MRNA',\n",
    "    'TSLA',\n",
    "    'TNA',\n",
    "    'GLD',\n",
    "    'SLV',\n",
    "    'USO',\n",
    "    'BAC',\n",
    "    'CVX',\n",
    "    'XOM',\n",
    "    'QQQ',\n",
    "    'MSFT',\n",
    "    'NVDA',\n",
    "    'WMT',\n",
    "    'BA',\n",
    "    'DIS',\n",
    "    'CAT',\n",
    "    'IBM',\n",
    "    'WFC',\n",
    "    'PLTR',\n",
    "    'AMD',\n",
    "    'AVGO',\n",
    "    'HOOD',\n",
    "    'CRWV',\n",
    "    'MSTR',\n",
    "    'UNH',\n",
    "    'GOOG',\n",
    "    'APP',\n",
    "    'UBER'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45af73-58d0-42dd-87bc-cc71a71ea72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d=df_d.rename(columns={'datetime': 'fecha'})\n",
    "df_d['fecha'] = pd.to_datetime(df_d['fecha'])\n",
    "df_dia = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    company = df_d.query(\"companyName==@ticker\").copy()\n",
    "    company.sort_values(by=['fecha'])\n",
    "    company['SMA20'] = company['Close'].rolling(20).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA40'] = company['Close'].rolling(40).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA100'] = company['Close'].rolling(100).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA200'] = company['Close'].rolling(200).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    df_dia = pd.concat([df_dia, company],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35daec33-1b08-4593-a4f8-6182e0c84683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h['datetime'] = pd.to_datetime(df_h['datetime'])\n",
    "df_h[\"fecha\"] = pd.to_datetime(df_h[\"datetime\"].dt.date)\n",
    "df_hora = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    company = df_h.query(\"companyName==@ticker\").copy()\n",
    "    company.sort_values(by=['datetime'])\n",
    "    company['SMA20'] = company['Close'].rolling(20).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA40'] = company['Close'].rolling(40).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA100'] = company['Close'].rolling(100).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA200'] = company['Close'].rolling(200).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    df_hora = pd.concat([df_hora, company],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209deb1a-7d45-4219-973a-7ffb4799b6fb",
   "metadata": {},
   "source": [
    "#### Detect Pivots/Fractals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a310f39-0bd7-4343-8d3f-a1dfbd780e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=17\n",
    "max_idx1 = argrelextrema(df_dia['Close'].values, np.greater, order=ord)[0]\n",
    "min_idx1 = argrelextrema(df_dia['Close'].values, np.less, order=ord)[0]\n",
    "# Aplicar el cálculo solo a los índices en la lista\n",
    "df_dia.loc[max_idx1, 'pivotHigh'] = df_dia['High']+1e-3\n",
    "df_dia.loc[min_idx1, 'pivotLow'] = df_dia['Low']-(1e-3)\n",
    "df_dia.loc[max_idx1, 'isPivot'] = 1\n",
    "df_dia.loc[min_idx1, 'isPivot'] = 2\n",
    "\n",
    "#HORA\n",
    "max_idx2 = argrelextrema(df_hora['Close'].values, np.greater, order=ord)[0]\n",
    "min_idx2 = argrelextrema(df_hora['Close'].values, np.less, order=ord)[0]\n",
    "# Aplicar el cálculo solo a los índices en la lista\n",
    "df_hora.loc[max_idx2, 'pivotHigh'] = df_hora['High']+1e-3\n",
    "df_hora.loc[min_idx2, 'pivotLow'] = df_hora['Low']-(1e-3)\n",
    "df_hora.loc[max_idx2, 'isPivot'] = 1\n",
    "df_hora.loc[min_idx2, 'isPivot'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fb96a-eb92-4fb7-8adf-a6104b87e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODIGO DE REVISION DIA\n",
    "dfpl = df_dia.iloc[0:150]\n",
    "\n",
    "p = figure(width=2500, height=500,\n",
    "        title=\"DIA\",\n",
    "        background_fill_color=\"#efefef\",\n",
    "        tooltips=[(\"Index\", \"@index\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\")]\n",
    "        )\n",
    "p.xaxis.major_label_orientation = 0.8 # radians\n",
    "p.x_range.range_padding = 0.05\n",
    "p.xaxis.axis_line_width = 2\n",
    "\n",
    "p.segment(\"index\", \"High\", \"index\",\"Low\",  color=\"black\", line_width=1, source=dfpl)\n",
    "\n",
    "inc = dfpl.query(\"Close>Open\")\n",
    "dec = dfpl.query(\"Open>Close\")\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"red\",\n",
    "    line_color=\"red\",    \n",
    "    source=dec   \n",
    ")\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"green\",\n",
    "    line_color=\"green\", \n",
    "    source=inc   \n",
    ")\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotHigh\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista\", source=dfpl[(dfpl.isPivot==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotLow\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista\", source=dfpl[(dfpl.isPivot==2)])\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d4b24-1446-4885-b99b-852e121f7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODIGO DE REVISION HORA\n",
    "dfpl = df_hora.iloc[0:150]\n",
    "\n",
    "p = figure(width=2500, height=500,\n",
    "        title=\"HORA\",\n",
    "        background_fill_color=\"#efefef\",\n",
    "        tooltips=[(\"Index\", \"@index\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\")]\n",
    "        )\n",
    "p.xaxis.major_label_orientation = 0.8 # radians\n",
    "p.x_range.range_padding = 0.05\n",
    "p.xaxis.axis_line_width = 2\n",
    "\n",
    "p.segment(\"index\", \"High\", \"index\",\"Low\",  color=\"black\", line_width=1, source=dfpl)\n",
    "\n",
    "inc = dfpl.query(\"Close>Open\")\n",
    "dec = dfpl.query(\"Open>Close\")\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"red\",\n",
    "    line_color=\"red\",    \n",
    "    source=dec   \n",
    ")\n",
    "\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"green\",\n",
    "    line_color=\"green\", \n",
    "    source=inc   \n",
    ")\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotHigh\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista\", source=dfpl[(dfpl.isPivot==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotLow\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista\", source=dfpl[(dfpl.isPivot==2)])\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0161c5f-b811-4bdf-9a52-dcaedf61980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cerca a PM100 o PM200 en diario o el PM20 bajo el PM40\n",
    "def zonabarata(df_dia):\n",
    "    if ((df_dia['isPivot']==2) & ((( df_dia['SMA100']-df_dia['Low']<=2 ) | ( df_dia['SMA200']-df_dia['Low']<=2 )) | (df_dia['SMA20']<df_dia['SMA40']) ) ):    \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_dia['zbarata'] = df_dia.apply(zonabarata, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91f41893-8197-48b3-8a91-9780afe8a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hora_final = pd.merge(df_hora, df_dia[['fecha','companyName', 'zbarata']], on = ['companyName','fecha'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517602b2-5dd0-4fff-9b48-18fa351c0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pga(df_hora_final):\n",
    "    if ((df_hora_final['zbarata']==1) & (df_hora_final['isPivot']==2)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_hora_final['pfuerte'] = df_hora_final.apply(pga, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91c48d4c-a1a6-4e6e-9624-58cff7dd47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vela verde\n",
    "df_hora_final['Vela_Verde'] = df_hora_final['Close'] > df_hora_final['Open']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b140a2-360e-48c2-96cc-74db7be4ce7b",
   "metadata": {},
   "source": [
    "### Detect Price Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f795429-366f-462c-b9d1-165ce5438e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_channel(candle, backevalTrend, trendH):\n",
    "\n",
    "    localdf = dfpl.loc[candle-backevalTrend:candle] #tomar en cuenta el backcandles\n",
    "    highs = localdf.loc[localdf.index.isin(trendH)].High.values\n",
    "    idxhighs = localdf.loc[localdf.index.isin(trendH)].High.index\n",
    "    \n",
    "    if len(highs)>=2:\n",
    "        sl_highs, interc_highs, r_value_h, _, _ = stats.linregress(idxhighs,highs)    \n",
    "        return(sl_highs, interc_highs, r_value_h**2)\n",
    "    else:\n",
    "        return(0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee188de-64f6-4d42-9615-b4255e6612f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backcandle(candle):\n",
    "    \n",
    "    trendH = []\n",
    "    backeval = 0\n",
    "    val = 0\n",
    "    \n",
    "    dfpl['PM40_PM20'] = dfpl['SMA40']-dfpl['SMA20']\n",
    "    idinicial = dfpl.index[0]\n",
    "    velas = candle - idinicial\n",
    "    \n",
    "    if(dfpl.loc[candle,\"PM40_PM20\"]>0):        \n",
    "        idx_negativo = dfpl.loc[:candle, 'PM40_PM20'][::-1].lt(0).idxmax()\n",
    "        #print(\"hito1\")\n",
    "        if (idx_negativo==candle):\n",
    "            backeval = candle - velas\n",
    "        else:\n",
    "            backeval = idx_negativo - 4\n",
    "    #print(\"hito2\")\n",
    "  \n",
    "    val = candle - backeval\n",
    "    \n",
    "    #print(\"hito3\")\n",
    "    #print(\"idx_negativo:\",idx_negativo)\n",
    "    \n",
    "    if(val>velas):\n",
    "        backeval=candle-velas\n",
    "    #print(\"hito4\")\n",
    "\n",
    "    #print(\"backeval:\",backeval)\n",
    "        \n",
    "    if((dfpl.loc[backeval,\"PM40_PM20\"]>0) & (val<velas)):\n",
    "        idx_negativo = dfpl.loc[:backeval, 'PM40_PM20'][::-1].lt(0).idxmax()\n",
    "        backeval = idx_negativo - 4    \n",
    "    #print(\"hito5\")\n",
    "\n",
    "    if val>velas:\n",
    "        backeval=candle-velas\n",
    "        \n",
    "    #print(\"hito6\")\n",
    "\n",
    "    #ini = candle - backeval\n",
    "    ini = backeval\n",
    "    trendprev=dfpl.loc[ini:candle]\n",
    "    trend = trendprev.reset_index(drop=False)\n",
    "\n",
    "    idxhighs = trend.index.to_numpy().reshape(-1,1) # Convertir X a una matriz 2D\n",
    "    highs = trend.High.values\n",
    "    modelo1 = LinearRegression()\n",
    "    modelo1.fit(idxhighs, highs)\n",
    "    # Obtener la predicción de la línea de regresión\n",
    "    Y_pred = modelo1.predict(idxhighs)\n",
    "    # Calcular la distancia solo de los puntos que están POR ENCIMA de la línea\n",
    "    trend['Distancia'] = trend[\"High\"] - Y_pred  # Diferencia entre el valor real y la predicción\n",
    "    # Filtrar los puntos que están por encima (donde Y > Y_pred, es decir, Distancia > 0)\n",
    "    df_encima = trend[trend['Distancia'] > 0]\n",
    "    puntos_mas_lejanos = df_encima.nlargest(2, 'Distancia')   #2 puntos mas lejanos    \n",
    "    trendH = puntos_mas_lejanos[\"index\"].tolist()\n",
    "    \n",
    "    puntos_mas_lejanos2 = trend.tail(10).nlargest(2, 'Distancia')\n",
    "    trendH2 = puntos_mas_lejanos2[\"index\"].tolist()\n",
    "    \n",
    "    trendH.extend(trendH2)\n",
    "    trendH.append(candle)  #add ultimo candle\n",
    "    #print(trendH)\n",
    "    return trendH, backeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5556c-2df4-4dec-9391-5bd8757ced2c",
   "metadata": {},
   "source": [
    "### Detect Break Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768d05b-6e13-4ce1-a46f-ba7009590045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendChannel(row,candle, backeval, window, sl_highs, interc_highs):\n",
    "\n",
    "    if (candle-backeval-window)<0:\n",
    "        return np.nan\n",
    "    ini=candle-backeval\n",
    "    fin=candle+window\n",
    "    trendcurrhigh = np.where(np.logical_or((row.index > fin),  (row.index <  ini)), np.nan, (sl_highs*row.index + interc_highs))\n",
    "    return trendcurrhigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fab76-8866-4388-890f-37f154b4a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBreakOut(candleEval,backcandles, window, start, candle):\n",
    "    if (candleEval-backcandles-window)<0:\n",
    "        return 0\n",
    "\n",
    "    if candleEval==start:\n",
    "        prev_idx = candleEval\n",
    "    else:\n",
    "        prev_idx = candleEval-1\n",
    "        \n",
    "    prev_high = dfpl.loc[prev_idx].High\n",
    "    prev_low = dfpl.loc[prev_idx].Low\n",
    "    prev_close = dfpl.loc[prev_idx].Close\n",
    "    \n",
    "    curr_idx = candleEval\n",
    "    curr_high = dfpl.loc[candleEval].High\n",
    "    curr_low = dfpl.loc[candleEval].Low\n",
    "    curr_close = dfpl.loc[candleEval].Close\n",
    "    curr_open = dfpl.loc[candleEval].Open\n",
    "\n",
    "    trend_prevhigh=dfpl.loc[prev_idx].trendcurrhigh\n",
    "\n",
    "    trend_currhigh=dfpl.loc[candleEval].trendcurrhigh\n",
    "    \n",
    "    if ( prev_low < trend_prevhigh and\n",
    "        prev_close > trend_prevhigh and\n",
    "        curr_open > trend_currhigh and\n",
    "        curr_close > trend_currhigh and\n",
    "        candleEval>candle): #and r_sq_h > 0.9\n",
    "        return 2\n",
    "\n",
    "    elif (curr_open > trend_currhigh and\n",
    "        curr_close > trend_currhigh and candleEval>candle):\n",
    "        return 3\n",
    "    \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4841bb97-442d-480a-b7db-6452ccb51cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakpointpos(x):\n",
    "    if x['isBreakOutIni'] in (2,3):\n",
    "        return x['Low']+3e-3\n",
    "    elif x['isBreakOutIni']==1:\n",
    "        return x['High']-3e-3\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba19c4-6693-47aa-8e8c-4c75ae62d2ea",
   "metadata": {},
   "source": [
    "##### Hallando casos de Ruptura del Canal Bajista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8236f-8f9d-49f2-b21c-350a7f789c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revisionVelas(dfpl, backeval,window, candle):\n",
    "    #Revision de Velas\n",
    "    #Promedio del volumen de 50 velas antes del posible caso\n",
    "    promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "    #puede darse cualquiera de estas condiciones: \n",
    "    # - que la vela sea verde, que tenga volumen, este por encima de la linea trend y que tenga cuerpo (cierra por encima de su tercera parte)\n",
    "    # - que la vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "    j=candle+1\n",
    "    k=candle+window\n",
    "    ind_vela=0\n",
    "    \n",
    "    maxindex = dfpl.index[-1]\n",
    "    if (k>maxindex):\n",
    "        k=maxindex\n",
    "    \n",
    "    #Evaluacion de velas ALCISTAS\n",
    "    dfpl[\"cdlengulfing\"] = ta.CDLENGULFING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlhammer\"] = ta.CDLHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmorningstar\"] = ta.CDLMORNINGSTAR(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlpiercing\"] = ta.CDLPIERCING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlclosingmarubozu\"] = ta.CDLCLOSINGMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmarubozu\"] = ta.CDLMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdl3whitesoldiers\"] = ta.CDL3WHITESOLDIERS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharami\"] = ta.CDLHARAMI(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharamicross\"] = ta.CDLHARAMICROSS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlinvertdhammer\"] = ta.CDLINVERTEDHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlladderbottom\"] = ta.CDLLADDERBOTTOM(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "\n",
    "    dfpl['Vela_Verde'] = dfpl['Close'] > dfpl['Open']\n",
    "    # Calcular el nivel de la tercera parte\n",
    "    dfpl['Third_Level'] = dfpl['Open'] + (dfpl['High'] - dfpl['Low']) / 3\n",
    "    # Verificar si la vela cierra por encima de su tercera parte, vela con cuerpo\n",
    "    dfpl['Above_Third'] = dfpl['Close'] > dfpl['Third_Level']\n",
    "\n",
    "    while j<=k:            \n",
    "        \n",
    "        vol = dfpl.loc[j,\"Volume\"]\n",
    "        above_Third = dfpl.loc[j,\"Above_Third\"]\n",
    "        vela_Verde = dfpl.loc[j,\"Vela_Verde\"]\n",
    "        lineTrend = dfpl.loc[j,'trendcurrhigh']\n",
    "        high = dfpl.loc[j,'High']\n",
    "        close = dfpl.loc[j,'Close']\n",
    "\n",
    "        cdlengulfing = dfpl.loc[j,\"cdlengulfing\"]\n",
    "        cdlhammer = dfpl.loc[j,\"cdlhammer\"]\n",
    "        cdlmorningstar = dfpl.loc[j,\"cdlmorningstar\"]\n",
    "        cdlpiercing = dfpl.loc[j,\"cdlpiercing\"]\n",
    "        cdlclosingmarubozu = dfpl.loc[j,\"cdlclosingmarubozu\"]\n",
    "        cdlmarubozu = dfpl.loc[j,\"cdlmarubozu\"]\n",
    "        cdl3whitesoldiers = dfpl.loc[j,\"cdl3whitesoldiers\"]\n",
    "        cdlharami = dfpl.loc[j,\"cdlharami\"]\n",
    "        cdlharamicross = dfpl.loc[j,\"cdlharamicross\"]\n",
    "        cdlinvertdhammer = dfpl.loc[j,\"cdlinvertdhammer\"]\n",
    "        cdlladderbottom = dfpl.loc[j,\"cdlladderbottom\"]\n",
    "\n",
    "        #vela consecutiva alcista\n",
    "        candle_up = (\n",
    "                     dfpl.loc[j,\"High\"]> dfpl.loc[j-1,\"High\"]\n",
    "                     and dfpl.loc[j-1,\"High\"]> dfpl.loc[j,\"Low\"]\n",
    "                     and dfpl.loc[j,\"Low\"]> dfpl.loc[j-2,\"High\"]\n",
    "                     and dfpl.loc[j-2,\"High\"]> dfpl.loc[j-1,\"Low\"]\n",
    "                     and dfpl.loc[j-1,\"Low\"]> dfpl.loc[j-3,\"High\"]\n",
    "                     and dfpl.loc[j-3,\"High\"]> dfpl.loc[j-2,\"Low\"]\n",
    "                     and dfpl.loc[j-2,\"Low\"]> dfpl.loc[j-3,\"Low\"]\n",
    "                    )\n",
    "\n",
    "        if (candle_up==True and close>lineTrend):\n",
    "            ind_vela=ind_vela+1\n",
    "            \n",
    "        j=j+1\n",
    "    \n",
    "    return 1 #1 para mostrar todo ind_vela para que funcione el filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356713ec-eef9-4fe4-a974-2c6aeabe26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert caso: 721 SPY\n",
      "insert caso: 1551 SPY\n",
      "insert caso: 2216 SPY\n",
      "insert caso: 2493 SPY\n",
      "insert caso: 4278 META\n",
      "insert caso: 5166 META\n",
      "insert caso: 6851 META\n",
      "insert caso: 7838 AAPL\n",
      "insert caso: 8172 AAPL\n",
      "insert caso: 8673 AAPL\n",
      "insert caso: 9185 AAPL\n",
      "insert caso: 9628 AAPL\n",
      "insert caso: 9976 AAPL\n",
      "insert caso: 10359 AAPL\n"
     ]
    }
   ],
   "source": [
    "df_casos = pd.DataFrame()\n",
    "caso = 0\n",
    "ticker2 = \"\"\n",
    "window=5\n",
    "backeval=75\n",
    "backevalTrend=0\n",
    "dfpl = pd.DataFrame\n",
    "trendH = []\n",
    "trendL = []\n",
    "cant = 0\n",
    "for i, row in df_hora_final.iterrows():\n",
    "    #if (i==83382):\n",
    "    if(df_hora_final['pfuerte'][i]==1): #posibles casos \n",
    "        print(\"posible caso:\",i, df_hora_final['companyName'][i])\n",
    "        cant = 0\n",
    "        candle = i\n",
    "        cnt = 0\n",
    "        valiniHigh = df_hora_final.loc[candle,\"High\"]\n",
    "        #valiniLow = df.loc[candle,\"Low\"]\n",
    "        ticker = df_hora_final['companyName'][i]\n",
    "        #Reinicio de casos por company\n",
    "        if ticker2 != ticker:\n",
    "            ticker2 = ticker\n",
    "            caso = 0\n",
    "        dfpl = df_hora_final[(df_hora_final.companyName==ticker)].loc[i-backeval:i+backeval].copy()\n",
    "\n",
    "        #print(\"rowMin:\", dfpl.index[0],\", rowMax:\", dfpl.index[-1])\n",
    "                    \n",
    "        h=1\n",
    "        l=1\n",
    "\n",
    "        cant = cant +1\n",
    "        cantHorasTrend=0\n",
    "        #print(\"opcionH:\",h,\"opcionL:\",l)\n",
    "        trendH, backevalTrend = backcandle(candle)\n",
    "        #print (\"-->trendH:\",trendH)\n",
    "        #print (\"-->backevalTrend:\",backevalTrend)    \n",
    "        \n",
    "        #cantHorasTrend = (dfpl.loc[candle,\"datetime\"] - dfpl.loc[backevalTrend,\"datetime\"]).total_seconds() / 3600\n",
    "\n",
    "        #if (cantHorasTrend>48): #Verificacion de caida por lo menos 2 dias\n",
    "        backevalTrend2 = candle - backevalTrend\n",
    "    \n",
    "                    \n",
    "        #revision de trend negativo indica que esta cayendo, solo me quedo con estos casos\n",
    "        sl_highs, interc_highs, r_sq_h = collect_channel(candle, backevalTrend2, trendH)\n",
    "                \n",
    "\n",
    "        #print(\"======:\", candle)\n",
    "        #print(\"===trendH===\")\n",
    "        #print(trendH)\n",
    "        #print(\"===trendL===\")\n",
    "        #print(trendL)\n",
    "        dfpl.loc[trendH, \"trendH\"] = 1\n",
    "    \n",
    "        \n",
    "        #print(\"sl_highs:\", sl_highs, \", sl_lows:\", sl_lows, \", r_sq_h:\", r_sq_h)\n",
    "        if (sl_highs<=0): #solo tendencias a la baja and ind_vela>0 sl_lows<0 and r_sq_h>=0.7  and sl_highs<=-0.1 and ind_vela>0\n",
    "            #print(\"paso1\")\n",
    "            #crear linea de tendencia high y low\n",
    "            dfpl['trendcurrhigh']  = trendChannel(dfpl,candle,backevalTrend2,window,sl_highs,interc_highs)\n",
    "            \n",
    "            #ind_vela = revisionVelas(dfpl, backeval,window, candle)\n",
    "            ind_vela = 1\n",
    "            promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "\n",
    "            #print(\"ind_vela:\",ind_vela)\n",
    "            if (ind_vela>0):\n",
    "                #print(\"paso2\")\n",
    "                dfpl[\"bearishSlope\"] = np.nan #pendiente bajista en vacio\n",
    "                dfpl.loc[i, \"bearishSlope\"] = 1 #pendiente bajista solo al punto evaluado            \n",
    "                dfpl[\"ind_posicion\"] = 0\n",
    "                dfpl.loc[(dfpl.index < i), 'ind_posicion'] = -1\n",
    "                dfpl.loc[(dfpl.index > i), 'ind_posicion'] = 1\n",
    "                dfpl[\"promVol\"] = promVol\n",
    "                #dfpl[\"sl_highs\"] = sl_highs\n",
    "                #dfpl[\"r_sq_h\"] = r_sq_h\n",
    "        \n",
    "                start = dfpl.index[0]\n",
    "                dfpl[\"isBreakOut\"] = [isBreakOut(candleEval, backevalTrend2, window, start, candle) for candleEval in dfpl.index]\n",
    "                # Solo me quedo con el primer BREAK OUT\n",
    "                cnt = dfpl.query(\"isBreakOut in (2,3) and Close>Open\").shape[0] \n",
    "                id=0\n",
    "                id2=0\n",
    "                #print(\"paso3\")\n",
    "                if cnt>0:\n",
    "                    #print(\"paso4\")\n",
    "                    id = dfpl.query(\"isBreakOut in (2,3) and Close>Open\").index[0]                        \n",
    "                    #dfpl['isBreakOutIni'] = np.where(id!=dfpl.index, np.nan, dfpl['isBreakOut'])                        \n",
    "                    dfpl.loc[id,'isBreakOutIni'] = 1\n",
    "                    #print(\"paso5\")\n",
    "                    k=0\n",
    "                    while (k<=3):\n",
    "                        dfpl['breakpointpos'] = dfpl.apply(lambda row: breakpointpos(row), axis=1)\n",
    "                        cnt2 = dfpl.query(\"index>@id and isPivot==1\").shape[0]\n",
    "                        #print(\"paso6\")\n",
    "                        if cnt2>0:\n",
    "                            id2 = dfpl.query(\"index>@id and isPivot==1\").index[0]\n",
    "                            dfpl.loc[id2,'isBreakOutFinal'] = 1\n",
    "                            k=4\n",
    "                            #print(\"paso7\")\n",
    "                        else:\n",
    "                            #revisar 25 velas mas\n",
    "                            #print(\"paso8\")\n",
    "                            idfinal = dfpl.index[-1] \n",
    "                            idfinal2 = idfinal+25\n",
    "                            if idfinal2 in df_hora_final[df_hora_final['companyName']==ticker].index:\n",
    "                                dfpl2 = df_hora_final[(df_hora_final.companyName==ticker)].loc[idfinal+1:idfinal2].copy()\n",
    "                                dfpl = pd.concat([dfpl, dfpl2],ignore_index=False)\n",
    "                                #cnt2 = dfpl.query(\"index>@id and isPivot==1\").shape[0]                    \n",
    "                                #if cnt2>0:\n",
    "                                #    id2 = dfpl.query(\"index>@id and isPivot==1\").index[0]\n",
    "                                #    dfpl.loc[id2,'isBreakOutFinal'] = 1\n",
    "                                #else:\n",
    "                                #    dfpl['isBreakOutFinal'] = np.nan\n",
    "                            else:\n",
    "                                dfpl['isBreakOutFinal'] = np.nan  \n",
    "                            k=k+1\n",
    "                    \n",
    "                else:\n",
    "                    dfpl['isBreakOutIni'] = np.nan                        \n",
    "                    dfpl['breakpointpos'] = np.nan\n",
    "        \n",
    "                if cnt>0:\n",
    "                    #INSERT CASO\n",
    "                    caso=caso+1   \n",
    "                    print(\"insert caso:\",i, df_hora_final['companyName'][i])\n",
    "                    dfpl[\"caso\"] = caso                        \n",
    "                    if len(df_casos)<1:\n",
    "                        df_casos = dfpl\n",
    "                    else:\n",
    "                        df_casos = pd.concat([df_casos, dfpl],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b9b8e-724e-4626-b5ca-ad32b1a48f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/pfuerte_h.txt'\n",
    "\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    df_casos.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648944f-0175-4b89-9166-35e564665dc4",
   "metadata": {},
   "source": [
    "##### BACKTESTING\n",
    "###### Usando paquete backtesting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f8ef78b-d223-4cd5-81ca-e55055976336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos2 = df_casos.query(\"isBreakOutIni==1 or isBreakOutFinal==1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9d491ebc-64db-40f7-9508-da2ef8dd5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== BACKTESTING ================= #\n",
    "# obteniendo dataframe backtesting\n",
    "df_backTesting = pd.merge(df_hora_final, df_casos2[['datetime','companyName', 'isBreakOutIni','isBreakOutFinal','caso']], on = ['companyName','datetime'], how='left')\n",
    "# datos de trade se asigna una vela anterior debido a que backtesting.py toma entra como la siguiente vela\n",
    "df_backTesting['isBreakOutIni'] = df_backTesting['isBreakOutIni'].shift(-1)\n",
    "df_backTesting['isBreakOutFinal'] = df_backTesting['isBreakOutFinal'].shift(-1)\n",
    "#modificamos indice con el compo datetime\n",
    "df_backTesting.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573594ee-623b-4a80-97fb-4259a4f70b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategia\n",
    "class strategyPisoFuerte(Strategy):    \n",
    "    def init(self):        \n",
    "        self.breakout_entry = self.I(lambda x: x, self.data.isBreakOutIni) #Indica la señal entrada al backtesting\n",
    "        self.breakout_exit = self.I(lambda x: x, self.data.isBreakOutFinal) #Indica la señal salida al backtesting\n",
    "\n",
    "    def next(self):       \n",
    "        if self.breakout_entry[-1] == 1:\n",
    "            self.buy()  #COMPRA\n",
    "        elif self.breakout_exit[-1] == 1 and self.position:\n",
    "            self.position.close() #CIERRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8511b1d-e075-4d93-96e4-989cbde8ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/2679 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para SPY:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_13728\\1399598466.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/2754 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para META:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_13728\\1399598466.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/2714 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para AAPL:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_13728\\1399598466.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    }
   ],
   "source": [
    "# Por cada TIcket\n",
    "my_stats = {}\n",
    "estadisticas = pd.DataFrame()          # lista para ticker\n",
    "tradesprev = pd.DataFrame()     # lista para cada caso por ticker\n",
    "for ticker in df_backTesting['companyName'].unique():\n",
    "    ticker_data = df_backTesting[df_backTesting['companyName'] == ticker].copy() #Filtro por cada ticker\n",
    "    bt = Backtest(ticker_data, strategyPisoFuerte, cash=10_000)\n",
    "    my_stats = bt.run()\n",
    "    listTrades = my_stats['_trades']\n",
    "    tradesdf = pd.DataFrame(listTrades) #trades\n",
    "    tradesdf['Ticker'] = ticker\n",
    "    stats_filter={\n",
    "        'Ticker':ticker,\n",
    "        'EntryTime':my_stats['Start'],\n",
    "        'ExitTime':my_stats['End'],\n",
    "        'Return [%]': my_stats['Return [%]'],\n",
    "        'CAGR [%]': my_stats['Return (Ann.) [%]'],\n",
    "        'Sharpe Ratio': my_stats['Sharpe Ratio'],\n",
    "        'Max. Drawdown [%]': my_stats['Max. Drawdown [%]'],\n",
    "        'Win Rate [%]': my_stats['Win Rate [%]'],\n",
    "        '# Trades': my_stats['# Trades'],\n",
    "        'Expectancy [%]': my_stats['Expectancy [%]'],\n",
    "        'Profit Factor': my_stats['Profit Factor'],\n",
    "        'Duration': my_stats['Duration'],\n",
    "        'Avg. Trade [%]':my_stats['Avg. Trade [%]'],\n",
    "        'Max. Trade Duration':my_stats['Max. Trade Duration'],\n",
    "        'Avg. Trade Duration':my_stats['Avg. Trade Duration']\n",
    "    }\n",
    "    stat=pd.DataFrame([stats_filter])\n",
    "    if tradesprev.shape[0]==0:\n",
    "        tradesprev = tradesdf.copy()\n",
    "        estadisticas=stat.copy()\n",
    "    else:\n",
    "        tradesprev = pd.concat([tradesprev, tradesdf],ignore_index=True)\n",
    "        estadisticas=pd.concat([estadisticas, stat],ignore_index=True)\n",
    "    # Mostramos\n",
    "    #bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5227501d-6b0d-47c6-9c69-d788c10f2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = df_casos2[(df_casos2['isBreakOutIni']==1)].copy()\n",
    "df_casos3_ini=ini.rename(columns={'Open': 'EntryPrice', 'datetime': 'EntryTime', 'companyName': 'Ticker'})[['EntryPrice','Ticker','caso','EntryTime']]\n",
    "final = df_casos2[(df_casos2['isBreakOutFinal']==1)].copy()\n",
    "df_casos3_final=final.rename(columns={'Open': 'ExitPrice', 'datetime': 'ExitTime', 'companyName': 'Ticker'})[['ExitPrice','Ticker','caso','ExitTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "665ebabb-cb9a-4bc1-86e5-a104dfd1496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos3=df_casos3_ini.merge(df_casos3_final,on=['Ticker','caso'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "97d478f6-89ca-4f57-a323-74e71b972187",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.merge(df_casos3, tradesprev, on = ['EntryTime','Ticker'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0d09c951-126d-46ed-896c-dc0ad6c35058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitPrice(x):\n",
    "    if pd.isna(x['ExitPrice_x']):\n",
    "        return x['ExitPrice_y']\n",
    "    else:\n",
    "        return x['ExitPrice_x']\n",
    "trades['ExitPrice'] = trades.apply(lambda row: exitPrice(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "259a2845-bb98-4b60-a8ee-e3b553741564",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.rename(columns={'EntryPrice_x': 'EntryPrice'})\n",
    "trades = trades.drop(['EntryPrice_y','ExitPrice_x', 'ExitPrice_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97c42ae5-be6d-4934-8442-8a35530eeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitTime(x):\n",
    "    if pd.isna(x['ExitTime_x']):\n",
    "        return x['ExitTime_y']\n",
    "    else:\n",
    "        return x['ExitTime_x']\n",
    "trades['ExitTime'] = trades.apply(lambda row: exitTime(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "929dd667-1188-4b3e-800c-7299558c0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(x):\n",
    "    if pd.isna(x['Duration']):\n",
    "        if pd.isna(x['ExitTime']):\n",
    "            return pd.NaT\n",
    "        else:\n",
    "            return x['ExitTime']-x['EntryTime']\n",
    "    else:\n",
    "        return x['Duration']\n",
    "trades['Duration'] = trades.apply(lambda row: duration(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ec29de7e-f261-48a2-b6ab-006b7c508ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.drop(['ExitTime_x', 'ExitTime_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f0ce0242-c9b1-4dd1-aa39-fe17bd507bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades=trades[['Ticker','EntryTime','ExitTime','EntryPrice','ExitPrice','Duration','Size','EntryBar','ExitBar','ReturnPct','caso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in estadisticas['Ticker'].unique():\n",
    "    count = trades[trades[\"Ticker\"] == item].shape[0]\n",
    "    estadisticas.loc[estadisticas['Ticker'] == item, '# Trades'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c95d67-0c03-4025-bb3b-abfa3f8e0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/backtesting'\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "path_trades = os.path.join(path, 'trades_pfuerte.txt')\n",
    "path_estadisticas = os.path.join(path, 'estadisticas_pfuerte.txt')\n",
    "\n",
    "for file_path in [path_trades, path_estadisticas]:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"File does not exist: {file_path}. It will be created.\")\n",
    "\n",
    "trades.to_csv(path_trades, header=True, index=False, sep='\\t', mode='w')\n",
    "estadisticas.to_csv(path_estadisticas, header=True, index=False, sep='\\t', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
