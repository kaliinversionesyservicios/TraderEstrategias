{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35c8a88-6a78-4301-9093-219c00c77439",
   "metadata": {},
   "source": [
    "## Estrategia de Promedio Movil de 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d718db-91d1-4aeb-890e-19c6cd8147d5",
   "metadata": {},
   "source": [
    "###### 1. PM20 debe estar por encima del PM40 en HORA\n",
    "###### 2. Estar en una tendencia Alcista: el PM de 20 sobre el PM de 40 y el de 40 por encima del PM de 100 y este ultimo por encima del PM de 200, (mandatorio debe de ser 20 sobre 40) El PM de 20 y de 40 deben verse paralelos como lineas de ferrocarril.\n",
    "###### 3. Necesito una caida debemos estar cerca o tocar el PM de 40 en hora \n",
    "Que los precios toquen o se acerquen al PM de 4 \n",
    "Trazo una linea bajista siquiendo la cai a\n",
    "Cuando una vela verde Alcista, vela final rompe la linea baji ta\n",
    "despues de las 11:00am se compra un call for 1, 2 days, buy 10 cont y ponle el l mit\n",
    "Cuando los precios estan lejos del PM40 es zona cara, y cerca del PM de 40 es zona b rata\n",
    "La mayoria de las veces el mercado sube 1, 2 dias maximo y despues cae nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1419602-f4c4-4654-b46a-a2880e633d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "#import matplotlib.pyplot as plt\n",
    "#import math\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "from bokeh.plotting import figure, show, column\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from backtesting import Backtest, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0033ba-0def-4ec6-9598-f0db6074bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h=pd.read_csv('data/dataxh.txt',sep='\\t')\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META',\n",
    "    'AAPL',\n",
    "    'AMZN',\n",
    "    'NFLX',\n",
    "    'MRNA',\n",
    "    'TSLA',\n",
    "    'TNA',\n",
    "    'GLD',\n",
    "    'SLV',\n",
    "    'USO',\n",
    "    'BAC',\n",
    "    'CVX',\n",
    "    'XOM',\n",
    "    'QQQ',\n",
    "    'MSFT',\n",
    "    'NVDA',\n",
    "    'WMT',\n",
    "    'BA',\n",
    "    'DIS',\n",
    "    'CAT',\n",
    "    'IBM',\n",
    "    'WFC',\n",
    "    'PLTR',\n",
    "    'AMD',\n",
    "    'AVGO',\n",
    "    'HOOD',\n",
    "    'CRWV',\n",
    "    'MSTR',\n",
    "    'UNH',\n",
    "    'GOOG',\n",
    "    'APP',\n",
    "    'UBER'\n",
    "]\n",
    "\n",
    "#    'SPY',\n",
    "#    'META',\n",
    "#    'AAPL',\n",
    "#    'AMZN',\n",
    "#    'NFLX',\n",
    "#    'MRNA',\n",
    "#    'TSLA',\n",
    "#    'TNA',\n",
    "#    'GLD',\n",
    "#    'SLV',\n",
    "#    'USO',\n",
    "#    'BAC',\n",
    "#    'CVX',\n",
    "#    'XOM',\n",
    "#    'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "525e2503-1752-4bd8-98e1-df265b6fc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h['datetime'] = pd.to_datetime(df_h['datetime'])\n",
    "df = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    company = df_h.query(\"companyName==@ticker\").copy()\n",
    "    company.sort_values(by=['datetime'])\n",
    "    #company = yf.download(ticker, start = ini2_str, end = today_str, interval='60m')\n",
    "    #company.columns = [company.columns[0][0], company.columns[1][0], company.columns[2][0], company.columns[3][0], company.columns[4][0]]\n",
    "    #company.rename(columns={'Datetime':'Gmt time'}, inplace = True)\n",
    "    #company['datetime'] = pd.to_datetime (company.index)\n",
    "    #company['companyName'] = ticker\n",
    "    company['SMA20'] = company['Close'].rolling(20).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA40'] = company['Close'].rolling(40).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA100'] = company['Close'].rolling(100).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA200'] = company['Close'].rolling(200).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    \n",
    "    df = pd.concat([df, company],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d807db8-4ff5-47fd-9eb3-66ef8ef38eb3",
   "metadata": {},
   "source": [
    "### Detect Pivots/Fractals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "553a48af-971c-4caf-94de-4b1bd4cc40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=10\n",
    "#for ticker in tickers:\n",
    "#print(\"====\", ticker)\n",
    "#dfpl = df[(df.companyName==ticker)] #df.query(\"companyName=='AAPL'\")\n",
    "max_idx = argrelextrema(df['Close'].values, np.greater, order=ord)[0]\n",
    "min_idx = argrelextrema(df['Close'].values, np.less, order=ord)[0]\n",
    "#print(max_idx)\n",
    "#print(min_idx)\n",
    "#df['pivotHigh'] = np.nan\n",
    "#df['pivotLow'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "# Aplicar el cálculo solo a los índices en la lista\n",
    "df.loc[max_idx, 'pivotHigh'] = df['High']+1e-3\n",
    "df.loc[min_idx, 'pivotLow'] = df['Low']-(1e-3)\n",
    "df.loc[max_idx, 'isPivot'] = 1\n",
    "df.loc[min_idx, 'isPivot'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca565f31-ebd3-42d1-bb7e-5dbcbdb5cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODIGO DE REVISION CARLOS\n",
    "#dfpl = df.iloc[500:970]\n",
    "dfpl = df.iloc[0:200]\n",
    "\n",
    "p = figure(width=2500, height=500,\n",
    "        title=\"RCB\",\n",
    "        background_fill_color=\"#efefef\",\n",
    "        tooltips=[(\"Index\", \"@index\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\")]\n",
    "        )\n",
    "p.xaxis.major_label_orientation = 0.8 # radians\n",
    "p.x_range.range_padding = 0.05\n",
    "#p.xaxis.axis_line_join = \"bevel\" # radians\n",
    "p.xaxis.axis_line_width = 2\n",
    "\n",
    "p.segment(\"index\", \"High\", \"index\",\"Low\",  color=\"black\", line_width=1, source=dfpl)\n",
    "\n",
    "inc = dfpl.query(\"Close>Open\")\n",
    "dec = dfpl.query(\"Open>Close\")\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"red\",\n",
    "    line_color=\"red\",    \n",
    "    source=dec   \n",
    ")\n",
    "\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"green\",\n",
    "    line_color=\"green\", \n",
    "    source=inc   \n",
    ")\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotHigh\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista\", source=dfpl[(dfpl.isPivot==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotLow\", marker=\"circle\", size=10,\n",
    "           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista\", source=dfpl[(dfpl.isPivot==2)])\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f2430-623c-4a54-b577-a8bfc7f6269c",
   "metadata": {},
   "source": [
    "### Detectando casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1828d278-ae5e-4e36-9444-ff4d13eeb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punto de cambio a tendencia alcista\n",
    "def pm01(df):\n",
    "    #if ((df['pivotLow']>0) & ((df['Low']-df['SMA40'])<=1)):\n",
    "    if ((df['isPivot']==2) & ((df['Low']-df['SMA40'])<=1)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['pm40_01'] = df.apply(pm01, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ab9f28-5871-4c68-ada3-386c2876bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#el PM20 sobre el PM40, el PM40 por encima del PM100 y este ultimo por encima del PM200\n",
    "def pm02(df):\n",
    "    if ((df['SMA20'] >= df['SMA40']) & (df['SMA40'] >= df['SMA100']) & (df['SMA100'] >= df['SMA200'])):\n",
    "    #if ((df['SMA20'] >= df['SMA40']) & (df['SMA40'] >= df['SMA100'])):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['ind_SMA'] = df.apply(pm02, axis=1)\n",
    "\n",
    "def pm03(df):\n",
    "    if ((df['pm40_01'] >= 1) & (df['ind_SMA'] >= 1)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#numeracion de casos donde se dio el cambio de tendencia\n",
    "#df['id_posiblepm40'] = df.query(\"pm40_01==1 and ind_SMA==1\").groupby([\"companyName\"]).cumcount()+1\n",
    "df['id_posiblepm40'] = df.apply(pm03, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77788c46-9386-4bb5-b470-33cacb8cc645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"id_posiblepm40\"]>0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e80dd2-318b-4aed-9d06-a7674835a1f3",
   "metadata": {},
   "source": [
    "### Detect Price Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e072437-f29c-4514-aeac-e07eec14a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_channel(candle, backevalTrend, trendH):\n",
    "    #localdf = df[candle-backcandles-window:candle-window]\n",
    "    localdf = dfpl.loc[candle-backevalTrend:candle] #tomar en cuenta el backcandles\n",
    "    #localdf['isPivot'] = localdf.apply(lambda x: isPivot(x.name,window), axis=1)\n",
    "    \n",
    "    #highs = localdf.High.values\n",
    "    #idxhighs = localdf.High.index\n",
    "    #lows = localdf.Low.values\n",
    "    #idxlows = localdf.Low.index\n",
    "\n",
    "    highs = localdf.loc[localdf.index.isin(trendH)].High.values\n",
    "    idxhighs = localdf.loc[localdf.index.isin(trendH)].High.index\n",
    "    #lows = localdf.loc[localdf.index.isin(trendL)].Low.values\n",
    "    #idxlows = localdf.loc[localdf.index.isin(trendL)].Low.index\n",
    "\n",
    "    #highs = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 1)].High.values\n",
    "    #idxhighs = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 1)].High.index\n",
    "    #lows = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 2)].Low.values\n",
    "    #idxlows = localdf.loc[localdf.index.isin([candle]) | (localdf['isPivot'] == 2)].Low.index\n",
    "\n",
    "    #lows = localdf.loc[localdf.index.isin(trendL)].Low.values\n",
    "    #idxlows = localdf.loc[localdf.index.isin(trendL)].Low.index\n",
    "\n",
    "    #print(\"highs:\",highs)\n",
    "    #print(\"idxhighs:\",idxhighs)\n",
    "    #print(\"lows:\",lows)\n",
    "    #print(\"idxlows:\",idxlows)\n",
    "    #print (\"tamanio:\",localdf.shape[0])\n",
    "    \n",
    "    #if len(lows)>=2 and len(highs)>=2:\n",
    "    if len(highs)>=2:\n",
    "        #sl_lows, interc_lows, r_value_l, _, _ = stats.linregress(idxlows,lows)\n",
    "        sl_highs, interc_highs, r_value_h, _, _ = stats.linregress(idxhighs,highs)    \n",
    "        #return(sl_lows, interc_lows, sl_highs, interc_highs, r_value_l**2, r_value_h**2)\n",
    "        return(sl_highs, interc_highs, r_value_h**2)\n",
    "    else:\n",
    "        return(0,0,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0d8fd48-c9e5-412c-970d-9e32e8e3f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backcandle(candle):\n",
    "    \n",
    "    trendH = []\n",
    "    backeval = 0\n",
    "    val = 0\n",
    "    \n",
    "    #dfpl['PM40_PM20'] = dfpl['SMA40']-dfpl['SMA20']\n",
    "\n",
    "    # Tomar los valores hacia atrás desde el índice actual (sin incluirlo)\n",
    "    prev_vals = dfpl.loc[:candle - 1, 'ind_SMA']\n",
    "\n",
    "    # Buscar el último índice donde fue 0 (de atrás hacia adelante)\n",
    "    for i in reversed(prev_vals.index):\n",
    "        if dfpl.loc[i, 'ind_SMA'] == 0:\n",
    "            backeval = i - 4\n",
    "            break\n",
    "\n",
    "    val = candle - backeval\n",
    "\n",
    "    \n",
    "    \n",
    "    if val>75:\n",
    "        backeval=candle-75\n",
    "        \n",
    "    if (dfpl.loc[backeval,\"ind_SMA\"]>0):\n",
    "        idx_negativo = dfpl.loc[:backeval, 'ind_SMA'][::-1].lt(0).idxmax()\n",
    "        backeval = idx_negativo - 4\n",
    "\n",
    "    if val>75:\n",
    "        backeval=candle-75\n",
    "\n",
    "    #ini = candle - backeval\n",
    "    ini = backeval\n",
    "    trendprev=dfpl.loc[ini:candle]\n",
    "    trend = trendprev.reset_index(drop=False)\n",
    "\n",
    "    idxhighs = trend.index.to_numpy().reshape(-1,1) # Convertir X a una matriz 2D\n",
    "    highs = trend.High.values\n",
    "    modelo1 = LinearRegression()\n",
    "    modelo1.fit(idxhighs, highs)\n",
    "    # Obtener la predicción de la línea de regresión\n",
    "    Y_pred = modelo1.predict(idxhighs)\n",
    "    # Calcular la distancia solo de los puntos que están POR ENCIMA de la línea\n",
    "    trend['Distancia'] = trend[\"High\"] - Y_pred  # Diferencia entre el valor real y la predicción\n",
    "    # Filtrar los puntos que están por encima (donde Y > Y_pred, es decir, Distancia > 0)\n",
    "    df_encima = trend[trend['Distancia'] > 0]\n",
    "    puntos_mas_lejanos = df_encima.nlargest(2, 'Distancia')   #2 puntos mas lejanos\n",
    "    trendH = puntos_mas_lejanos[\"index\"].tolist()\n",
    "    trendH.append(candle)   \n",
    "    \n",
    "    return trendH, backeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5225ae-6d09-4f96-bd2f-f21b6dd0b4ca",
   "metadata": {},
   "source": [
    "### Detect Break Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ed21e2c-13e6-4d1a-81ed-c5aaac56f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendChannel(row,candle, backeval, window, sl_highs, interc_highs):\n",
    "\n",
    "    if (candle-backeval-window)<0:\n",
    "        return np.nan\n",
    "    ini=candle-backeval\n",
    "    fin=candle+window\n",
    "    trendcurrhigh = np.where(np.logical_or((row.index > fin),  (row.index <  ini)), np.nan, (sl_highs*row.index + interc_highs))\n",
    "    return trendcurrhigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af6d12d5-433c-43a2-9067-34bf3c26130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBreakOut(candleEval,backcandles, window, start, candle):\n",
    "    if (candleEval-backcandles-window)<0:\n",
    "        return 0\n",
    "\n",
    "    if candleEval==start:\n",
    "        prev_idx = candleEval\n",
    "    else:\n",
    "        prev_idx = candleEval-1\n",
    "        \n",
    "    prev_high = dfpl.loc[prev_idx].High\n",
    "    prev_low = dfpl.loc[prev_idx].Low\n",
    "    prev_close = df.loc[prev_idx].Close\n",
    "    \n",
    "    curr_idx = candleEval\n",
    "    curr_high = dfpl.loc[candleEval].High\n",
    "    curr_low = dfpl.loc[candleEval].Low\n",
    "    curr_close = dfpl.loc[candleEval].Close\n",
    "    curr_open = dfpl.loc[candleEval].Open\n",
    "\n",
    "    #trend_prevlow=dfpl.loc[prev_idx].trendcurrlow\n",
    "    trend_prevhigh=dfpl.loc[prev_idx].trendcurrhigh\n",
    "\n",
    "    #trend_currlow=dfpl.loc[candleEval].trendcurrlow\n",
    "    trend_currhigh=dfpl.loc[candleEval].trendcurrhigh\n",
    "\n",
    "    #codigo para tendencia LOW, nos importa breaks en tendencia HIGH\n",
    "    #if ( prev_high > trend_prevlow and\n",
    "    #    prev_close < trend_prevlow and\n",
    "    #    curr_open < trend_currlow and\n",
    "    #    curr_close < trend_currlow and candleEval>candle): #and r_sq_l > 0.9\n",
    "    #    return 1\n",
    "    \n",
    "    if ( prev_low < trend_prevhigh and\n",
    "        prev_close > trend_prevhigh and\n",
    "        curr_open > trend_currhigh and\n",
    "        curr_close > trend_currhigh and\n",
    "        candleEval>candle): #and r_sq_h > 0.9\n",
    "        return 2\n",
    "\n",
    "    elif (curr_open > trend_currhigh and\n",
    "        curr_close > trend_currhigh and candleEval>candle):\n",
    "        return 3\n",
    "    \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a6f7cd4-6144-46bb-8732-caab1da7e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakpointpos(x):\n",
    "    if x['isBreakOutIni'] in (2,3):\n",
    "        return x['Low']+3e-3\n",
    "    elif x['isBreakOutIni']==1:\n",
    "        return x['High']-3e-3\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b688bb9-64d4-474f-bd98-149ea3bf8908",
   "metadata": {},
   "source": [
    "### Hallando casos de Ruptura techo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "010106c7-0626-4c5b-ad49-ca9c023fdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revisionVelas(dfpl, backeval,window, candle):\n",
    "    #Revision de Velas\n",
    "    #Promedio del volumen de 50 velas antes del posible caso\n",
    "    promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "    #puede darse cualquiera de estas condiciones: \n",
    "    # - que la vela sea verde, que tenga volumen, este por encima de la linea trend y que tenga cuerpo (cierra por encima de su tercera parte)\n",
    "    # - que la vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "    j=candle+1\n",
    "    k=candle+window\n",
    "    ind_vela=0\n",
    "    \n",
    "    #k no puede pasrse del rango\n",
    "    maxindex = dfpl.index[-1]\n",
    "    if (k>maxindex):\n",
    "        k=maxindex\n",
    "    \n",
    "    #print(\"candle:\",candle)\n",
    "    #print(\"window:\",window)\n",
    "    #print(\"j:\",j, \",k:\",k)\n",
    "    \n",
    "    #Evaluacion de velas ALCISTAS\n",
    "    dfpl[\"cdlengulfing\"] = ta.CDLENGULFING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlhammer\"] = ta.CDLHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmorningstar\"] = ta.CDLMORNINGSTAR(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlpiercing\"] = ta.CDLPIERCING(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlclosingmarubozu\"] = ta.CDLCLOSINGMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlmarubozu\"] = ta.CDLMARUBOZU(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdl3whitesoldiers\"] = ta.CDL3WHITESOLDIERS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharami\"] = ta.CDLHARAMI(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlharamicross\"] = ta.CDLHARAMICROSS(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlinvertdhammer\"] = ta.CDLINVERTEDHAMMER(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "    dfpl[\"cdlladderbottom\"] = ta.CDLLADDERBOTTOM(dfpl['Open'], dfpl['High'], dfpl['Low'], dfpl['Close'])\n",
    "\n",
    "    dfpl['Vela_Verde'] = dfpl['Close'] > dfpl['Open']\n",
    "    # Calcular el nivel de la tercera parte\n",
    "    #dfpl['Third_Level'] = dfpl['Low'] + (dfpl['High'] - dfpl['Low']) / 3\n",
    "    dfpl['Third_Level'] = dfpl['Open'] + (dfpl['High'] - dfpl['Low']) / 3\n",
    "    # Verificar si la vela cierra por encima de su tercera parte, vela con cuerpo\n",
    "    dfpl['Above_Third'] = dfpl['Close'] > dfpl['Third_Level']\n",
    "\n",
    "    while j<=k:            \n",
    "        \n",
    "        vol = dfpl.loc[j,\"Volume\"]\n",
    "        above_Third = dfpl.loc[j,\"Above_Third\"]\n",
    "        vela_Verde = dfpl.loc[j,\"Vela_Verde\"]\n",
    "        lineTrend = dfpl.loc[j,'trendcurrhigh']\n",
    "        high = dfpl.loc[j,'High']\n",
    "        close = dfpl.loc[j,'Close']\n",
    "\n",
    "        cdlengulfing = dfpl.loc[j,\"cdlengulfing\"]\n",
    "        cdlhammer = dfpl.loc[j,\"cdlhammer\"]\n",
    "        cdlmorningstar = dfpl.loc[j,\"cdlmorningstar\"]\n",
    "        cdlpiercing = dfpl.loc[j,\"cdlpiercing\"]\n",
    "        cdlclosingmarubozu = dfpl.loc[j,\"cdlclosingmarubozu\"]\n",
    "        cdlmarubozu = dfpl.loc[j,\"cdlmarubozu\"]\n",
    "        cdl3whitesoldiers = dfpl.loc[j,\"cdl3whitesoldiers\"]\n",
    "        cdlharami = dfpl.loc[j,\"cdlharami\"]\n",
    "        cdlharamicross = dfpl.loc[j,\"cdlharamicross\"]\n",
    "        cdlinvertdhammer = dfpl.loc[j,\"cdlinvertdhammer\"]\n",
    "        cdlladderbottom = dfpl.loc[j,\"cdlladderbottom\"]\n",
    "\n",
    "        #vela consecutiva alcista\n",
    "        candle_up = (#dfpl.loc[j,\"Vela_Verde\"]==True \n",
    "                     #and dfpl.loc[j-1,\"Vela_Verde\"]==True \n",
    "                     dfpl.loc[j,\"High\"]> dfpl.loc[j-1,\"High\"]\n",
    "                     and dfpl.loc[j-1,\"High\"]> dfpl.loc[j,\"Low\"]\n",
    "                     and dfpl.loc[j,\"Low\"]> dfpl.loc[j-2,\"High\"]\n",
    "                     and dfpl.loc[j-2,\"High\"]> dfpl.loc[j-1,\"Low\"]\n",
    "                     and dfpl.loc[j-1,\"Low\"]> dfpl.loc[j-3,\"High\"]\n",
    "                     and dfpl.loc[j-3,\"High\"]> dfpl.loc[j-2,\"Low\"]\n",
    "                     and dfpl.loc[j-2,\"Low\"]> dfpl.loc[j-3,\"Low\"]\n",
    "                     #and dfpl.loc[j,\"Close\"]> dfpl.loc[j-1,\"High\"] \n",
    "                     #and dfpl.loc[j-1,\"Close\"]>dfpl.loc[j-2,\"High\"]\n",
    "                     #and dfpl.loc[j-1,\"Close\"]>dfpl.loc[j-3,\"High\"] \n",
    "                    )\n",
    "\n",
    "        if (candle_up==True and close>lineTrend):\n",
    "            ind_vela=ind_vela+1\n",
    "        #vela sea verde, que tenga volumen, que tenga cuerpo y que este por encima de la linea trend\n",
    "        #if (vela_Verde==True and promVol<=vol and above_Third==True and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1\n",
    "        \n",
    "        #vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "        #if (\n",
    "        #    (cdlhammer>0 or\n",
    "        #     cdlmorningstar>0 or\n",
    "        #     cdlpiercing>0 or\n",
    "        #     cdl3whitesoldiers>0 or\n",
    "        #     cdlharami>0 or\n",
    "        #     cdlharamicross>0 or\n",
    "        #     cdlinvertdhammer>0 or\n",
    "        #     cdlladderbottom>0\n",
    "        #    )\n",
    "        #    and promVol<=vol\n",
    "        #    and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1\n",
    "\n",
    "        #vela sea envolvente, alcista y que este por encima de la linea trend\n",
    "        #if (\n",
    "        #    (cdlclosingmarubozu>0 or\n",
    "        #     cdlmarubozu>0 or\n",
    "        #     cdlengulfing>0 or\n",
    "        #     cdlhammer>0\n",
    "        #    )\n",
    "        #    #and promVol<=vol\n",
    "        #    and close>=lineTrend):\n",
    "        #    ind_vela=ind_vela+1 \n",
    "            \n",
    "        j=j+1\n",
    "    \n",
    "    return 1 #1 para mostrar todo ind_vela para que funcione el filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f455fe2-6ea0-41c9-9fab-e231b8030440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 SPY\n",
      "275 SPY\n",
      "915 SPY\n",
      "985 SPY\n",
      "1101 SPY\n",
      "1174 SPY\n",
      "1236 SPY\n",
      "1271 SPY\n",
      "1334 SPY\n",
      "1357 SPY\n",
      "1387 SPY\n",
      "1440 SPY\n",
      "1462 SPY\n",
      "1726 SPY\n",
      "2183 SPY\n",
      "2415 SPY\n",
      "2684 SPY\n",
      "2920 SPY\n",
      "3380 SPY\n",
      "3789 META\n",
      "4147 META\n",
      "4588 META\n",
      "4664 META\n",
      "4726 META\n",
      "4756 META\n",
      "4824 META\n",
      "5386 META\n",
      "5622 META\n",
      "5885 META\n",
      "6167 META\n",
      "6883 META\n",
      "6915 META\n",
      "7226 AAPL\n",
      "7910 AAPL\n",
      "7945 AAPL\n",
      "8640 AAPL\n",
      "8706 AAPL\n",
      "8737 AAPL\n",
      "8782 AAPL\n",
      "8874 AAPL\n",
      "9398 AAPL\n",
      "9650 AAPL\n",
      "9706 AAPL\n",
      "10410 AAPL\n"
     ]
    }
   ],
   "source": [
    "df_casos = pd.DataFrame()\n",
    "caso = 0\n",
    "ticker2 = \"\"\n",
    "window=5\n",
    "backeval=75\n",
    "backevalTrend=0\n",
    "dfpl = pd.DataFrame\n",
    "trendH = []\n",
    "trendL = []\n",
    "cant = 0\n",
    "for i, row in df.iterrows():\n",
    "    #if (i<=200):\n",
    "    if(df['id_posiblepm40'][i]==1): #posibles casos \n",
    "        #print(\"posible caso:\",i, df['companyName'][i])\n",
    "        cant = 0\n",
    "        candle = i\n",
    "        cnt = 0\n",
    "        valiniHigh = df.loc[candle,\"High\"]\n",
    "        #valiniLow = df.loc[candle,\"Low\"]\n",
    "        ticker = df['companyName'][i]\n",
    "        #Reinicio de casos por company\n",
    "        if ticker2 != ticker:\n",
    "            ticker2 = ticker\n",
    "            caso = 0\n",
    "        dfpl = df[(df.companyName==ticker)].loc[i-backeval:i+backeval]       \n",
    "\n",
    "        #print(\"rowMin:\", dfpl.index[0],\", rowMax:\", dfpl.index[-1])\n",
    "                    \n",
    "        h=1\n",
    "        l=1\n",
    "\n",
    "        cant = cant +1\n",
    "        cantHorasTrend=0\n",
    "        #print(\"opcionH:\",h,\"opcionL:\",l)\n",
    "        trendH, backevalTrend = backcandle(candle)\n",
    "        #print (\"-->trendH:\",trendH)\n",
    "        #print (\"-->backevalTrend:\",backevalTrend)    \n",
    "        \n",
    "        cantHorasTrend = (dfpl.loc[candle,\"datetime\"] - dfpl.loc[backevalTrend,\"datetime\"]).total_seconds() / 3600\n",
    "\n",
    "        if (cantHorasTrend>48): #Verificacion de caida por lo menos 2 dias\n",
    "            backevalTrend2 = candle - backevalTrend\n",
    "            #print (\"backevalTrend2\", backevalTrend2)\n",
    "                        \n",
    "            #revision de trend negativo indica que esta cayendo, solo me quedo con estos casos\n",
    "            sl_highs, interc_highs, r_sq_h = collect_channel(candle, backevalTrend2, trendH)\n",
    "                    \n",
    "    \n",
    "            #print(\"======:\", candle)\n",
    "            #print(\"===trendH===\")\n",
    "            #print(trendH)\n",
    "            #print(\"===trendL===\")\n",
    "            #print(trendL)\n",
    "            dfpl.loc[trendH, \"trendH\"] = 1\n",
    "        \n",
    "            \n",
    "            #print(\"sl_highs:\", sl_highs, \", sl_lows:\", sl_lows, \", r_sq_h:\", r_sq_h)\n",
    "            if (sl_highs<=0): #solo tendencias a la baja and ind_vela>0 sl_lows<0 and r_sq_h>=0.7  and sl_highs<=-0.1 and ind_vela>0\n",
    "                \n",
    "                #crear linea de tendencia high y low\n",
    "                dfpl['trendcurrhigh']  = trendChannel(dfpl,candle,backevalTrend2,window,sl_highs,interc_highs)\n",
    "                \n",
    "                ind_vela = revisionVelas(dfpl, backeval,window, candle)\n",
    "                promVol = dfpl.loc[i-backeval:i][\"Volume\"].mean()\n",
    "    \n",
    "                #print(\"ind_vela:\",ind_vela)\n",
    "                if (ind_vela>0):\n",
    "                    dfpl[\"bearishSlope\"] = np.nan #pendiente bajista en vacio\n",
    "                    dfpl.loc[i, \"bearishSlope\"] = 1 #pendiente bajista solo al punto evaluado            \n",
    "                    dfpl[\"ind_posicion\"] = 0\n",
    "                    dfpl.loc[(dfpl.index < i), 'ind_posicion'] = -1\n",
    "                    dfpl.loc[(dfpl.index > i), 'ind_posicion'] = 1\n",
    "                    dfpl[\"promVol\"] = promVol\n",
    "                    dfpl[\"sl_highs\"] = sl_highs\n",
    "                    dfpl[\"r_sq_h\"] = r_sq_h\n",
    "            \n",
    "                    start = dfpl.index[0]\n",
    "                    dfpl[\"isBreakOut\"] = [isBreakOut(candleEval, backevalTrend2, window, start, candle) for candleEval in dfpl.index]\n",
    "                    # Solo me quedo con el primer BREAK OUT\n",
    "                    cnt = dfpl.query(\"isBreakOut in (2,3) and Close>Open\").shape[0] \n",
    "                    id=0\n",
    "                    id2=0\n",
    "                    if cnt>0:\n",
    "                        id = dfpl.query(\"isBreakOut in (2,3) and Close>Open\").index[0]                        \n",
    "                        #dfpl['isBreakOutIni'] = np.where(id!=dfpl.index, np.nan, dfpl['isBreakOut'])                        \n",
    "                        dfpl.loc[id,'isBreakOutIni'] = 1\n",
    "                        dfpl['breakpointpos'] = dfpl.apply(lambda row: breakpointpos(row), axis=1)\n",
    "                        cnt2 = dfpl.query(\"index>@id and isPivot==1\").shape[0]\n",
    "                        \n",
    "                        if cnt2>0:\n",
    "                            id2 = dfpl.query(\"index>@id and isPivot==1\").index[0]\n",
    "                            dfpl.loc[id2,'isBreakOutFinal'] = 1\n",
    "                        else:\n",
    "                            dfpl['isBreakOutFinal'] = np.nan                      \n",
    "                        \n",
    "                    else:\n",
    "                        dfpl['isBreakOutIni'] = np.nan                        \n",
    "                        dfpl['breakpointpos'] = np.nan\n",
    "            \n",
    "                    if cnt>0:\n",
    "                        #INSERT CASO\n",
    "                        caso=caso+1                            \n",
    "                        dfpl[\"caso\"] = caso\n",
    "                        print(i, df['companyName'][i])\n",
    "                        if len(df_casos)<1:\n",
    "                            df_casos = dfpl\n",
    "                        else:\n",
    "                            df_casos = pd.concat([df_casos, dfpl],ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1480ae2-fe16-4eb0-81ab-ef4ce196e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "path='data/pm40_h.txt'\n",
    "\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_casos.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58155aa8-89e2-495b-9bb7-2fedc5593ba0",
   "metadata": {},
   "source": [
    "##### BACKTESTING\n",
    "###### Usando paquete backtesting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81b56407-c411-4a45-9307-d2c4bc98f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos2 = df_casos.query(\"isBreakOutIni==1 or isBreakOutFinal==1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa84fdfd-5009-4938-aae8-e0f3c24b9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== BACKTESTING ================= #\n",
    "# obteniendo dataframe backtesting\n",
    "df_backTesting = pd.merge(df, df_casos2[['datetime','companyName', 'isBreakOutIni','isBreakOutFinal','caso']], on = ['companyName','datetime'], how='left')\n",
    "# datos de trade se asigna una vela anterior debido a que backtesting.py toma entra como la siguiente vela\n",
    "df_backTesting['isBreakOutIni'] = df_backTesting['isBreakOutIni'].shift(-1)\n",
    "df_backTesting['isBreakOutFinal'] = df_backTesting['isBreakOutFinal'].shift(-1)\n",
    "#modificamos indice con el compo datetime\n",
    "df_backTesting.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eda5186-b89d-4f72-8ebe-aff0d72c8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategia\n",
    "class strategyRupturaCanal(Strategy):    \n",
    "    def init(self):        \n",
    "        self.breakout_entry = self.I(lambda x: x, self.data.isBreakOutIni) #Indica la señal entrada al backtesting\n",
    "        self.breakout_exit = self.I(lambda x: x, self.data.isBreakOutFinal) #Indica la señal salida al backtesting\n",
    "\n",
    "    def next(self):       \n",
    "        #print(self.data)        \n",
    "        if self.breakout_entry[-1] == 1:\n",
    "            self.buy()  #COMPRA\n",
    "        elif self.breakout_exit[-1] == 1 and self.position:\n",
    "            self.position.close() #CIERRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf99c1-36d3-4cc2-b330-cc91e9b264c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e8ce2582bd459dae596759c01bf344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3219 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para SPY:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\LINDER\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LINDER\\AppData\\Local\\Temp\\ipykernel_14376\\2904632593.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc7752eeb8341d28c8ddfb74e4b1311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3176 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para META:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\LINDER\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LINDER\\AppData\\Local\\Temp\\ipykernel_14376\\2904632593.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef68ddce8943b3a633786386d9b6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3212 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LINDER\\anaconda3\\Lib\\site-packages\\backtesting\\backtesting.py:954: UserWarning: time=1761: Broker canceled the relative-sized order due to insufficient margin.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para AAPL:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\LINDER\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LINDER\\AppData\\Local\\Temp\\ipykernel_14376\\2904632593.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    }
   ],
   "source": [
    "# Por cada TIcket\n",
    "my_stats = {}\n",
    "estadisticas = pd.DataFrame()          # lista para ticker\n",
    "tradesprev = pd.DataFrame()     # lista para cada caso por ticker\n",
    "for ticker in df_backTesting['companyName'].unique():\n",
    "    ticker_data = df_backTesting[df_backTesting['companyName'] == ticker].copy() #Filtro por cada ticker\n",
    "    bt = Backtest(ticker_data, strategyRupturaCanal, cash=10_000)\n",
    "    my_stats = bt.run()\n",
    "    listTrades = my_stats['_trades']\n",
    "    tradesdf = pd.DataFrame(listTrades) #trades\n",
    "    tradesdf['Ticker'] = ticker\n",
    "    stats_filter={\n",
    "        'Ticker':ticker,\n",
    "        'EntryTime':my_stats['Start'],\n",
    "        'ExitTime':my_stats['End'],\n",
    "        'Return [%]': my_stats['Return [%]'],\n",
    "        'CAGR [%]': my_stats['Return (Ann.) [%]'],\n",
    "        'Sharpe Ratio': my_stats['Sharpe Ratio'],\n",
    "        'Max. Drawdown [%]': my_stats['Max. Drawdown [%]'],\n",
    "        'Win Rate [%]': my_stats['Win Rate [%]'],\n",
    "        '# Trades': my_stats['# Trades'],\n",
    "        'Expectancy [%]': my_stats['Expectancy [%]'],\n",
    "        'Profit Factor': my_stats['Profit Factor'],\n",
    "        'Duration': my_stats['Duration'],\n",
    "        'Avg. Trade [%]':my_stats['Avg. Trade [%]'],\n",
    "        'Max. Trade Duration':my_stats['Max. Trade Duration'],\n",
    "        'Avg. Trade Duration':my_stats['Avg. Trade Duration']\n",
    "    }\n",
    "    stat=pd.DataFrame([stats_filter])\n",
    "    if tradesprev.shape[0]==0:\n",
    "        tradesprev = tradesdf.copy()\n",
    "        estadisticas=stat.copy()\n",
    "    else:\n",
    "        tradesprev = pd.concat([tradesprev, tradesdf],ignore_index=True)\n",
    "        estadisticas=pd.concat([estadisticas, stat],ignore_index=True)\n",
    "    # Mostramos\n",
    "    #bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "290fee23-3c70-41ab-ad27-082629e59911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = df_casos2[(df_casos2['isBreakOutIni']==1)].copy()\n",
    "df_casos3_ini=ini.rename(columns={'Open': 'EntryPrice', 'datetime': 'EntryTime', 'companyName': 'Ticker'})[['EntryPrice','Ticker','caso','EntryTime']]\n",
    "final = df_casos2[(df_casos2['isBreakOutFinal']==1)].copy()\n",
    "df_casos3_final=final.rename(columns={'Open': 'ExitPrice', 'datetime': 'ExitTime', 'companyName': 'Ticker'})[['ExitPrice','Ticker','caso','ExitTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a176db0e-ecd5-468a-b7a1-d35b36c0deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casos3=df_casos3_ini.merge(df_casos3_final,on=['Ticker','caso'],how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2909fd9c-cd77-43e5-b70e-72b8bab78f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.merge(df_casos3, tradesprev, on = ['EntryTime','Ticker'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "587b12b4-260f-475f-8e14-e68966b00d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitPrice(x):\n",
    "    if pd.isna(x['ExitPrice_x']):\n",
    "        return x['ExitPrice_y']\n",
    "    else:\n",
    "        return x['ExitPrice_x']\n",
    "trades['ExitPrice'] = trades.apply(lambda row: exitPrice(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "708c3cf0-ae04-427d-8d3f-2b58ce9b9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.rename(columns={'EntryPrice_x': 'EntryPrice'})\n",
    "trades = trades.drop(['EntryPrice_y','ExitPrice_x', 'ExitPrice_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9d4432e-f546-45ce-9b6d-ffbff432b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitTime(x):\n",
    "    if pd.isna(x['ExitTime_x']):\n",
    "        return x['ExitTime_y']\n",
    "    else:\n",
    "        return x['ExitTime_x']\n",
    "trades['ExitTime'] = trades.apply(lambda row: exitTime(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bf05b22-2894-43da-ad56-7238bf881028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(x):\n",
    "    if pd.isna(x['Duration']):\n",
    "        if pd.isna(x['ExitTime']):\n",
    "            return pd.NaT\n",
    "        else:\n",
    "            return x['ExitTime']-x['EntryTime']\n",
    "    else:\n",
    "        return x['Duration']\n",
    "trades['Duration'] = trades.apply(lambda row: duration(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da7d1e97-a697-4049-af25-fb322feeec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = trades.drop(['ExitTime_x', 'ExitTime_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2c889c1-350b-4af1-954c-eaf4d0461630",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades=trades[['Ticker','EntryTime','ExitTime','EntryPrice','ExitPrice','Duration','Size','EntryBar','ExitBar','ReturnPct','caso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c25b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in estadisticas['Ticker'].unique():\n",
    "    count = trades[trades[\"Ticker\"] == item].shape[0]\n",
    "    estadisticas.loc[estadisticas['Ticker'] == item, '# Trades'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e849e85-fc02-48fe-b87c-13930032930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist: D:\\PRUEBAS\\trades_pm40.txt. It will be created.\n",
      "File does not exist: D:\\PRUEBAS\\estadisticas_pm40.txt. It will be created.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/backtesting'\n",
    "\n",
    "os.makedirs(path,exist_ok=True)\n",
    "\n",
    "path_trades = os.path.join(path, 'trades_pm40.txt')\n",
    "path_estadisticas = os.path.join(path, 'estadisticas_pm40.txt')\n",
    "\n",
    "for file_path in [path_trades, path_estadisticas]:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    else:\n",
    "        print(f\"File does not exist: {file_path}. It will be created.\")\n",
    "\n",
    "trades.to_csv(path_trades, header=True, index=False, sep='\\t', mode='w')\n",
    "estadisticas.to_csv(path_estadisticas, header=True, index=False, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224c94a-a32c-4378-a570-c4e5d1e8e05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
