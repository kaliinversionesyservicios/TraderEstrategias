{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc8c365-0e93-457e-ad66-891325753697",
   "metadata": {},
   "source": [
    "### Detectar formacion de canal Bajista - Alcista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32069d8-6b85-4e0b-8684-0491e2d82cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "from bokeh.plotting import figure, show, column\n",
    "from bokeh.models import NumeralTickFormatter, Span\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5daf27d8-629e-4e60-9bd5-5a3d679a0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = pd.read_csv(r\"D:\\traderxpro\\data\\dataxh.txt\", sep=\"\\t\")\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META'\n",
    "]\n",
    "\n",
    "#    'SPY',\n",
    "#    'META',\n",
    "#    'AAPL',\n",
    "#    'AMZN',\n",
    "#    'NFLX',\n",
    "#    'MRNA',\n",
    "#    'TSLA',\n",
    "#    'TNA',\n",
    "#    'GLD',\n",
    "#    'SLV',\n",
    "#    'USO',\n",
    "#    'BAC',\n",
    "#    'CVX',\n",
    "#    'XOM',\n",
    "#    'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc30206c-7f79-44f6-95d9-613e74ce2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h['datetime'] = pd.to_datetime(df_h['datetime'])\n",
    "df = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    company = df_h.query(\"companyName==@ticker\").copy()\n",
    "    company.sort_values(by=['datetime'])\n",
    "    #company = yf.download(ticker, start = ini2_str, end = today_str, interval='60m')\n",
    "    #company.columns = [company.columns[0][0], company.columns[1][0], company.columns[2][0], company.columns[3][0], company.columns[4][0]]\n",
    "    #company.rename(columns={'Datetime':'Gmt time'}, inplace = True)\n",
    "    #company['datetime'] = pd.to_datetime (company.index)\n",
    "    #company['companyName'] = ticker\n",
    "    company['SMA35'] = company['Close'].rolling(35).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['SMA50'] = company['Close'].rolling(50).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['EMA35'] = company['Close'].ewm(span=35, adjust=False).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    company['EMA50'] = company['Close'].ewm(span=50, adjust=False).mean()\n",
    "    company.dropna(inplace=False)\n",
    "    \n",
    "    #company['SMA100'] = company['Close'].rolling(100).mean()\n",
    "    #company.dropna(inplace=False)\n",
    "    #company['SMA200'] = company['Close'].rolling(200).mean()\n",
    "    #company.dropna(inplace=False)\n",
    "    \n",
    "    df = pd.concat([df, company],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5346546-9111-4e7b-84d1-c12f8d95440d",
   "metadata": {},
   "source": [
    "### Detect Pivots/Fractals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd60166-c58f-49df-8d16-14bfb15dc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=15\n",
    "ord2=5\n",
    "#for ticker in tickers:\n",
    "#print(\"====\", ticker)\n",
    "#dfpl = df[(df.companyName==ticker)] #df.query(\"companyName=='AAPL'\")\n",
    "max_idx = argrelextrema(df['Close'].values, np.greater, order=ord)[0]\n",
    "min_idx = argrelextrema(df['Close'].values, np.less, order=ord)[0]\n",
    "\n",
    "max_idx2 = argrelextrema(df['Close'].values, np.greater, order=ord2)[0]\n",
    "min_idx2 = argrelextrema(df['Close'].values, np.less, order=ord2)[0]\n",
    "#print(max_idx)\n",
    "#print(min_idx)\n",
    "#df['pivotHigh'] = np.nan\n",
    "#df['pivotLow'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "#df['isPivot'] = np.nan\n",
    "# Aplicar el cálculo solo a los índices en la lista\n",
    "df.loc[max_idx, 'pivotHigh'] = df['High']+1e-3\n",
    "df.loc[min_idx, 'pivotLow'] = df['Low']-(1e-3)\n",
    "df.loc[max_idx, 'isPivot'] = 1\n",
    "df.loc[min_idx, 'isPivot'] = 2\n",
    "\n",
    "df.loc[max_idx2, 'pivotHigh2'] = df['High']+1e-3\n",
    "df.loc[min_idx2, 'pivotLow2'] = df['Low']-(1e-3)\n",
    "df.loc[max_idx2, 'isPivot2'] = 1\n",
    "df.loc[min_idx2, 'isPivot2'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384241bc-d996-48d8-b2de-20e08ce0c915",
   "metadata": {},
   "source": [
    "###### Canales bajistas, \n",
    "###### - Cuando el PM de 40 esta por encima del PM de 20 en direccion desendente\n",
    "###### - Cuando se dan el cruce de medias moviles 35 y 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d7a6e1-d77f-4351-8ee6-152367e11836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['cruce_medias']) # Drops column 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3b71db-79dc-4584-bd27-196f5409d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Señal: 1 = compra, -1 = venta, 0 = nada\n",
    "#df['prev_SMA35'] = df['SMA35'].shift(1)\n",
    "#df['prev_SMA50'] = df['SMA50'].shift(1)\n",
    "df['prev_EMA35'] = df['EMA35'].shift(1)\n",
    "df['prev_EMA50'] = df['EMA50'].shift(1)\n",
    "\n",
    "\n",
    "#Cruce de medias\n",
    "#df['cruce_medias'] = 0\n",
    "#df.loc[(df['prev_SMA35'] < df['prev_SMA50']) & (df['SMA35'] > df['SMA50']), 'cruce_medias'] = 1  # Golden Cross (Compra)\n",
    "#df.loc[(df['prev_SMA35'] > df['prev_SMA50']) & (df['SMA35'] < df['SMA50']), 'cruce_medias'] = -1 # Death Cross (Venta)\n",
    "\n",
    "df['cruce_medias'] = 0\n",
    "df.loc[(df['prev_EMA35'] < df['prev_EMA50']) & (df['EMA35'] > df['EMA50']), 'cruce_medias'] = 1  # Golden Cross (Compra)\n",
    "df.loc[(df['prev_EMA35'] > df['prev_EMA50']) & (df['EMA35'] < df['EMA50']), 'cruce_medias'] = -1 # Death Cross (Venta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c5beb4-d251-49d9-9cc7-f568f2893c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cdlengulfing\"] = ta.CDLENGULFING(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlhammer\"] = ta.CDLHAMMER(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlmorningstar\"] = ta.CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlpiercing\"] = ta.CDLPIERCING(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlclosingmarubozu\"] = ta.CDLCLOSINGMARUBOZU(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlmarubozu\"] = ta.CDLMARUBOZU(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdl3whitesoldiers\"] = ta.CDL3WHITESOLDIERS(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlharami\"] = ta.CDLHARAMI(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlharamicross\"] = ta.CDLHARAMICROSS(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlinvertdhammer\"] = ta.CDLINVERTEDHAMMER(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df[\"cdlladderbottom\"] = ta.CDLLADDERBOTTOM(df['Open'], df['High'], df['Low'], df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423a981d-bc33-48fb-9884-7dc67e01d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['indcaso']) # Drops column 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892faa84-350c-40ea-940c-265fcab38348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posible caso: 116 SPY ==> BAJA\n",
      "116 SPY , cruce medias: -1 , slope35: -0.01664558094338607 , slope50: -0.016549370147725048\n",
      "posible caso: 127 SPY ==> ALZA\n",
      "127 SPY , cruce medias: 1 , slope35: 0.21773070179993398 , slope50: 0.17567901098930683\n",
      "posible caso: 296 SPY ==> BAJA\n",
      "296 SPY , cruce medias: -1 , slope35: -0.18260069239277693 , slope50: -0.14115856762456722\n",
      "posible caso: 424 SPY ==> ALZA\n",
      "424 SPY , cruce medias: 1 , slope35: 0.17555931383133686 , slope50: 0.1670111630075893\n",
      "posible caso: 478 SPY ==> BAJA\n",
      "posible caso: 479 SPY ==> ALZA\n",
      "479 SPY , cruce medias: 1 , slope35: 0.041496018790358025 , slope50: 0.03303738684991981\n",
      "posible caso: 512 SPY ==> BAJA\n",
      "512 SPY , cruce medias: -1 , slope35: -0.15445522331443726 , slope50: -0.12313649778838845\n",
      "posible caso: 626 SPY ==> ALZA\n",
      "posible caso: 680 SPY ==> BAJA\n",
      "posible caso: 748 SPY ==> ALZA\n",
      "posible caso: 1033 SPY ==> BAJA\n",
      "1033 SPY , cruce medias: -1 , slope35: -0.11455394346089216 , slope50: -0.09734176410930492\n",
      "posible caso: 1062 SPY ==> ALZA\n",
      "1062 SPY , cruce medias: 1 , slope35: 0.15386077133013756 , slope50: 0.11737145120869896\n",
      "posible caso: 1475 SPY ==> BAJA\n",
      "1475 SPY , cruce medias: -1 , slope35: -0.11178856266566299 , slope50: -0.08167795110047109\n",
      "posible caso: 1587 SPY ==> ALZA\n",
      "posible caso: 1604 SPY ==> BAJA\n",
      "posible caso: 1618 SPY ==> ALZA\n",
      "posible caso: 1745 SPY ==> BAJA\n",
      "1745 SPY , cruce medias: -1 , slope35: -0.23751910259959005 , slope50: -0.18236966096729118\n",
      "posible caso: 1771 SPY ==> ALZA\n",
      "posible caso: 1977 SPY ==> BAJA\n",
      "1977 SPY , cruce medias: -1 , slope35: -0.14935895153640255 , slope50: -0.12449996159828222\n",
      "posible caso: 2100 SPY ==> ALZA\n",
      "2100 SPY , cruce medias: 1 , slope35: 0.4989666958607685 , slope50: 0.4449937247127592\n",
      "posible caso: 2201 SPY ==> BAJA\n",
      "posible caso: 2248 SPY ==> ALZA\n",
      "posible caso: 2457 SPY ==> BAJA\n",
      "posible caso: 2459 SPY ==> ALZA\n",
      "posible caso: 2487 SPY ==> BAJA\n",
      "posible caso: 2518 SPY ==> ALZA\n",
      "posible caso: 2577 SPY ==> BAJA\n",
      "posible caso: 2597 SPY ==> ALZA\n",
      "posible caso: 2719 SPY ==> BAJA\n",
      "posible caso: 2839 SPY ==> ALZA\n",
      "posible caso: 2927 SPY ==> BAJA\n",
      "posible caso: 2930 SPY ==> ALZA\n",
      "2930 SPY , cruce medias: 1 , slope35: 0.08787811892132397 , slope50: 0.07153550465902887\n",
      "posible caso: 3011 SPY ==> BAJA\n",
      "posible caso: 3153 SPY ==> ALZA\n",
      "posible caso: 3181 SPY ==> BAJA\n",
      "3181 SPY , cruce medias: -1 , slope35: -0.279930914017293 , slope50: -0.24227290921902228\n",
      "posible caso: 3265 SPY ==> ALZA\n",
      "posible caso: 3276 SPY ==> BAJA\n",
      "3276 SPY , cruce medias: -1 , slope35: -0.38275671472046807 , slope50: -0.3083399558323607\n",
      "posible caso: 3303 SPY ==> ALZA\n",
      "posible caso: 3519 SPY ==> BAJA\n",
      "posible caso: 3526 SPY ==> ALZA\n",
      "3526 SPY , cruce medias: 1 , slope35: 0.16423820144034001 , slope50: 0.12384923001064674\n",
      "posible caso: 3568 META ==> ALZA\n",
      "posible caso: 3597 META ==> BAJA\n",
      "posible caso: 3628 META ==> ALZA\n",
      "3628 META , cruce medias: 1 , slope35: 0.11034743672726109 , slope50: 0.08125694993552202\n",
      "posible caso: 3805 META ==> BAJA\n",
      "3805 META , cruce medias: -1 , slope35: -0.23640554398283584 , slope50: -0.2143210467122674\n",
      "posible caso: 3830 META ==> ALZA\n",
      "3830 META , cruce medias: 1 , slope35: 0.7192091572340928 , slope50: 0.5753449592216253\n",
      "posible caso: 3892 META ==> BAJA\n",
      "3892 META , cruce medias: -1 , slope35: -0.27756635306535243 , slope50: -0.22701392623430236\n",
      "posible caso: 3997 META ==> ALZA\n",
      "3997 META , cruce medias: 1 , slope35: 0.20402468773835825 , slope50: 0.16230544584439013\n",
      "posible caso: 4101 META ==> BAJA\n",
      "4101 META , cruce medias: -1 , slope35: -0.08291874217021288 , slope50: -0.0708588289197392\n",
      "posible caso: 4141 META ==> ALZA\n",
      "4141 META , cruce medias: 1 , slope35: 0.15594714087796516 , slope50: 0.11636862001594506\n",
      "posible caso: 4248 META ==> BAJA\n",
      "4248 META , cruce medias: -1 , slope35: -0.16829001610861763 , slope50: -0.13721284020531369\n",
      "posible caso: 4316 META ==> ALZA\n",
      "posible caso: 4441 META ==> BAJA\n",
      "posible caso: 4498 META ==> ALZA\n",
      "4498 META , cruce medias: 1 , slope35: 0.3452583804169994 , slope50: 0.264799352446039\n",
      "posible caso: 4596 META ==> BAJA\n",
      "4596 META , cruce medias: -1 , slope35: -0.12002687226527682 , slope50: -0.0959089956905587\n",
      "posible caso: 4614 META ==> ALZA\n",
      "posible caso: 4943 META ==> BAJA\n",
      "4943 META , cruce medias: -1 , slope35: -0.19532501699854585 , slope50: -0.1661515132908723\n",
      "posible caso: 4968 META ==> ALZA\n",
      "posible caso: 5005 META ==> BAJA\n",
      "5005 META , cruce medias: -1 , slope35: -0.5397680301107746 , slope50: -0.4055867498236846\n",
      "posible caso: 5032 META ==> ALZA\n",
      "posible caso: 5088 META ==> BAJA\n",
      "posible caso: 5199 META ==> ALZA\n",
      "posible caso: 5271 META ==> BAJA\n",
      "posible caso: 5273 META ==> ALZA\n",
      "posible caso: 5277 META ==> BAJA\n",
      "posible caso: 5288 META ==> ALZA\n",
      "5288 META , cruce medias: 1 , slope35: 0.042096385993874476 , slope50: 0.057217459313260645\n",
      "posible caso: 5314 META ==> BAJA\n",
      "5314 META , cruce medias: -1 , slope35: -0.31750430492771314 , slope50: -0.25216118217620365\n",
      "posible caso: 5328 META ==> ALZA\n",
      "posible caso: 5510 META ==> BAJA\n",
      "5510 META , cruce medias: -1 , slope35: -1.2142074456700835 , slope50: -0.9975391161641181\n",
      "posible caso: 5606 META ==> ALZA\n",
      "5606 META , cruce medias: 1 , slope35: 0.337981607803887 , slope50: 0.2918523636919701\n",
      "posible caso: 5735 META ==> BAJA\n",
      "5735 META , cruce medias: -1 , slope35: -0.2993697151919365 , slope50: -0.23436815860450827\n",
      "posible caso: 5813 META ==> ALZA\n",
      "5813 META , cruce medias: 1 , slope35: 0.5423945487102609 , slope50: 0.40785886471642435\n",
      "posible caso: 5980 META ==> BAJA\n",
      "posible caso: 6040 META ==> ALZA\n",
      "6040 META , cruce medias: 1 , slope35: 0.38356236084131345 , slope50: 0.32349209582777516\n",
      "posible caso: 6060 META ==> BAJA\n",
      "6060 META , cruce medias: -1 , slope35: -0.4317111622453038 , slope50: -0.3500767798962943\n",
      "posible caso: 6091 META ==> ALZA\n",
      "6091 META , cruce medias: 1 , slope35: 0.5107912137847372 , slope50: 0.39884079544829404\n",
      "posible caso: 6129 META ==> BAJA\n",
      "6129 META , cruce medias: -1 , slope35: -0.6295651582335674 , slope50: -0.544396299653682\n",
      "posible caso: 6184 META ==> ALZA\n",
      "posible caso: 6289 META ==> BAJA\n",
      "6289 META , cruce medias: -1 , slope35: -0.7159444168090341 , slope50: -0.5807463844178257\n",
      "posible caso: 6354 META ==> ALZA\n",
      "posible caso: 6390 META ==> BAJA\n",
      "posible caso: 6397 META ==> ALZA\n",
      "6397 META , cruce medias: 1 , slope35: 0.47871960184143064 , slope50: 0.35153039822432675\n",
      "posible caso: 6563 META ==> BAJA\n",
      "6563 META , cruce medias: -1 , slope35: -1.3245052758955171 , slope50: -1.0739623107389655\n",
      "posible caso: 6723 META ==> ALZA\n",
      "posible caso: 6746 META ==> BAJA\n",
      "6746 META , cruce medias: -1 , slope35: -0.8156894140069998 , slope50: -0.6984194435861345\n",
      "posible caso: 6878 META ==> ALZA\n"
     ]
    }
   ],
   "source": [
    "df_casos = pd.DataFrame()\n",
    "caso = 0\n",
    "ticker2 = \"\"\n",
    "window=5\n",
    "backeval=75\n",
    "backevalTrend=0\n",
    "dfpl = pd.DataFrame\n",
    "trendH = []\n",
    "trendL = []\n",
    "\n",
    "ispivot=0\n",
    "for i, row in df.iterrows():\n",
    "    #if (i==512):\n",
    "    cant = 0\n",
    "    cant2 = 0\n",
    "    ind_sl=0\n",
    "    ind_trendHL=0\n",
    "\n",
    "    ticker = df['companyName'][i]\n",
    "    #Reinicio de casos por company\n",
    "    if ticker2 != ticker:\n",
    "        ticker2 = ticker\n",
    "        caso = 0\n",
    "    dfpl = df[(df.companyName==ticker)].loc[i-backeval:i+backeval].copy()\n",
    "            \n",
    "    #if (dfpl[\"cruce_medias\"][i]==-1):\n",
    "    #    #print(\"posible caso a la BAJA:\",i, df['companyName'][i])\n",
    "    #    ispivot=1\n",
    "    #    ispivot2=2\n",
    "    #    if (sl<0):\n",
    "    #        #print(\"h1\")\n",
    "    #        ind_sl=1\n",
    "    #\n",
    "    #elif (dfpl[\"cruce_medias\"][i]==1):\n",
    "    #    #print(\"posible caso a la ALZA:\",i, df['companyName'][i])\n",
    "    #    ispivot=2\n",
    "    #    ispivot2=1\n",
    "    #    if (sl>0):\n",
    "    #        #print(\"h2\")\n",
    "    #        ind_sl=1\n",
    "    ind_sl=0\n",
    "    tipo=\"\"\n",
    "    if ((dfpl[\"cruce_medias\"][i]==-1) | (dfpl[\"cruce_medias\"][i]==1)):\n",
    "        if (dfpl[\"cruce_medias\"][i]==-1):\n",
    "           tipo=\"BAJA\" \n",
    "        else:\n",
    "            tipo=\"ALZA\"\n",
    "        print(\"posible caso:\",i, df['companyName'][i], \"==>\", tipo)\n",
    "\n",
    "        #Se dio el cruce de medias, antes existio un pivot high aprox 2 dias como maximo\n",
    "        fecha= dfpl['datetime'][i]\n",
    "        #fecha_limite = dfpl['datetime'][i] - pd.Timedelta(days=2) #resta dias calendarios\n",
    "        fecha_limite = dfpl['datetime'][i] - pd.offsets.BDay(2) #resta dias laborables\n",
    "        #print(\"fecha:\", dfpl['datetime'][i] ,\", fecha_limite:\", fecha_limite)\n",
    "        \n",
    "        #cnt1 = dfpl.query(\"isPivot==@ispivot and datetime>=@fecha_limite and datetime<=@fecha\")[\"isPivot\"].count()\n",
    "        #cnt2 = dfpl.query(\"isPivot==@ispivot2 and datetime>=@fecha_limite and datetime<=@fecha\")[\"isPivot\"].count()\n",
    "\n",
    "        cnt1=1\n",
    "        cnt2=0\n",
    "\n",
    "        indiceFinal=0\n",
    "        \n",
    "        #print(\"cantidad:\", cnt)\n",
    "        if (cnt1>0 and cnt2==0):\n",
    "            #Obtener casos      \n",
    "            #print(\"h00\")\n",
    "            if (dfpl[\"cruce_medias\"][i]==1): #ALCISTA               \n",
    "                #ALZA, velas por encima de promedios moviles\n",
    "                #ultimo high por encima y ultimo low cerca a los promedios\n",
    "                siguiente_H = dfpl[(dfpl.index>=i) & ((dfpl[\"isPivot\"]==1) | (dfpl[\"isPivot2\"]==1))].head(1)\n",
    "                if (siguiente_H.shape[0]>0):\n",
    "                    if (siguiente_H.iloc[0]['High']>siguiente_H.iloc[0]['EMA35']):\n",
    "                        indice = siguiente_H.index[0]\n",
    "                        siguiente_L = dfpl[(dfpl.index>indice) & ((dfpl[\"isPivot\"]==2) | (dfpl[\"isPivot2\"]==2))].head(1)\n",
    "                        if (siguiente_L.shape[0]>0):\n",
    "                            if (((siguiente_L.iloc[0]['Low']-siguiente_L.iloc[0]['EMA35'])<1) &  (siguiente_L.iloc[0]['Low']<siguiente_H.iloc[0]['High'])):\n",
    "                                indiceFinal = siguiente_L.index[0]\n",
    "\n",
    "            elif (dfpl[\"cruce_medias\"][i]==-1): #BAJISTA                    \n",
    "                #BAJA, velas por debajo de promedios moviles\n",
    "                #ultimo low por debajo y ultimo high cerca a los promedios\n",
    "                #print(\"h01\")\n",
    "                siguiente_L = dfpl[(dfpl.index>=i) & ((dfpl[\"isPivot\"]==2) | (dfpl[\"isPivot2\"]==2)) ].head(1)\n",
    "                if (siguiente_L.shape[0]>0):\n",
    "                    #print(\"h02\")\n",
    "                    if (siguiente_L.iloc[0]['Low']<siguiente_L.iloc[0]['EMA35']):\n",
    "                        #print(\"h03\")\n",
    "                        indice = siguiente_L.index[0]\n",
    "                        #print(\"indice:\", indice)\n",
    "                        siguiente_H = dfpl[(dfpl.index>indice) & ((dfpl[\"isPivot\"]==1) | (dfpl[\"isPivot2\"]==1))].head(1)\n",
    "                        if (siguiente_H.shape[0]>0):\n",
    "                            #print(\"h04:\",siguiente_H.index[0])\n",
    "                            if (((siguiente_H.iloc[0]['EMA35']-siguiente_H.iloc[0]['High'])<1) & (siguiente_H.iloc[0]['High']>siguiente_L.iloc[0]['Low'])):\n",
    "                                #print(\"h05\")\n",
    "                                indiceFinal = siguiente_H.index[0]\n",
    "\n",
    "            #print (\"indiceFinal:\", indiceFinal)\n",
    "            if (indiceFinal>0):\n",
    "                #print(\"h0\")\n",
    "                ultimos_2H = dfpl[(dfpl[\"isPivot\"]==1) | (dfpl[\"isPivot2\"]==1)].loc[:indiceFinal].tail(2)\n",
    "                ultimos_2L = dfpl[(dfpl[\"isPivot\"]==2) | (dfpl[\"isPivot2\"]==2)].loc[:indiceFinal].tail(2)\n",
    "                    \n",
    "                if (ultimos_2H.shape[0]==2 & ultimos_2L.shape[0]==2):\n",
    "                    #print(\"h1\")\n",
    "                    penultimo_valorH = ultimos_2H.iloc[0]['High']\n",
    "                    ultimo_valorH = ultimos_2H.iloc[1]['High']\n",
    "                    penultimo_valorL = ultimos_2L.iloc[0]['Low']\n",
    "                    ultimo_valorL = ultimos_2L.iloc[1]['Low']\n",
    "\n",
    "                    #En caso de tendencia ALCISTA\n",
    "                    #tomar los 2 ultimos HH – Higher High (Maximos mas Altos)\n",
    "                    #tomar los 2 ultimos HL – Higher Low (Maximos mas bajos)\n",
    "                    if (dfpl[\"cruce_medias\"][i]==1): #ALCISTA\n",
    "                        #print(\"h2\")\n",
    "                        if ((ultimo_valorH>penultimo_valorH) | (ultimo_valorL>penultimo_valorL)):\n",
    "                            #print(\"h21\")\n",
    "                            ind_trendHL=1\n",
    "\n",
    "                    #En caso de tendencia BAJISTA\n",
    "                    #tomar los 2 ultimos LH – Lower High (Minimos mas Altos)\n",
    "                    #tomar los 2 ultimos LL – Lower Low (Minimos mas bajos)\n",
    "                    elif (dfpl[\"cruce_medias\"][i]==-1): #BAJISTA\n",
    "                        #print(\"h3\")\n",
    "                        if ((ultimo_valorH<penultimo_valorH) | (ultimo_valorL<penultimo_valorL)):\n",
    "                            #print(\"h31\")\n",
    "                            ind_trendHL=1\n",
    "\n",
    "            #print(\"indiceFinal:\",indiceFinal,\",ind_trendHL:\",ind_trendHL)\n",
    "\n",
    "            if (indiceFinal>0):\n",
    "                #Inicio determinar slope que indica tendencia al ALZA o a la BAJA\n",
    "                medias35 = dfpl.loc[i:indiceFinal].EMA35.values\n",
    "                idxmedias35 = dfpl.loc[i:indiceFinal].EMA35.index\n",
    "                medias50 = dfpl.loc[i:indiceFinal].EMA50.values\n",
    "                idxmedias50 = dfpl.loc[i:indiceFinal].EMA50.index\n",
    "                if ((len(medias35)>=2) and  (len(medias50)>=2)):\n",
    "                    sl35, interc35, r_value35, _, _ = stats.linregress(idxmedias35,medias35)\n",
    "                    sl50, interc50, r_value50, _, _ = stats.linregress(idxmedias50,medias50)\n",
    "                #Fin slope\n",
    "        \n",
    "                if (dfpl[\"cruce_medias\"][i]==1): #ALCISTA\n",
    "                    #Revision de pendiente\n",
    "                    if (sl35>0 and sl50>0 #Pendiente positiva\n",
    "                       #and np.isclose(sl35, sl50, atol=1e-5) #Verificar si son paralelas\n",
    "                       #and interc35>interc50 #La línea 35 está por encima de la línea 50\n",
    "                       ):\n",
    "                        ind_sl=1\n",
    "                elif (dfpl[\"cruce_medias\"][i]==-1): #BAJISTA \n",
    "                    #Revision de pendiente\n",
    "                    if (sl35<0 and sl50<0 #Pendiente negativa\n",
    "                        #and np.isclose(sl35, sl50, atol=1e-5) #Verificar si son paralelas\n",
    "                        #and interc50>interc35 #La línea 50 está por encima de la línea 35\n",
    "                       ):\n",
    "                        ind_sl=1\n",
    "    \n",
    "            #print(\"sl35:\",sl35,\"sl50:\",sl50)\n",
    "            #print(\"interc35:\",interc35,\"interc50:\",interc50, \", ind_sl:\", ind_sl)\n",
    "\n",
    "            \n",
    "            \n",
    "            if ((indiceFinal>0) and (ind_trendHL>0) and (ind_sl>0)):\n",
    "                #print(\"h4\")\n",
    "                #INSERT CASO\n",
    "                caso=caso+1\n",
    "                dfpl.loc[i,'ind_posicion']=0\n",
    "               \n",
    "\n",
    "                #Final de caso es siguiente Pivot\n",
    "                if (dfpl[\"cruce_medias\"][i]==1): #ALCISTA\n",
    "                    dfpl.loc[indiceFinal,'isBreakOutIni']=1\n",
    "                    k=0\n",
    "                    while (k<=3):\n",
    "                        cnt2 = dfpl.query(\"index>@indiceFinal and isPivot==1\").shape[0]\n",
    "                        if cnt2>0:        \n",
    "                            id2 = dfpl.query(\"index>@indiceFinal and isPivot==1\").index[0]\n",
    "                            dfpl.loc[id2,'isBreakOutFinal'] = 1\n",
    "                            k=4\n",
    "                        else:\n",
    "                            idfinal = dfpl.index[-1] \n",
    "                            idfinal2 = idfinal+25\n",
    "                            if idfinal2 in df[df['companyName']==ticker].index:\n",
    "                                dfpl2 = df[(df.companyName==ticker)].loc[idfinal+1:idfinal2].copy()\n",
    "                                dfpl = pd.concat([dfpl, dfpl2],ignore_index=False)                           \n",
    "                            else:                  \n",
    "                                dfpl['isBreakOutFinal'] = np.nan\n",
    "                            k=k+1\n",
    "                           \n",
    "                \n",
    "                        \n",
    "                elif (dfpl[\"cruce_medias\"][i]==-1): #BAJISTA\n",
    "                    dfpl.loc[indiceFinal,'isBreakOutIni']=-1\n",
    "                    k=0\n",
    "                    while (k<=3):\n",
    "                        cnt2 = dfpl.query(\"index>@indiceFinal and isPivot==2\").shape[0]\n",
    "                        if cnt2>0:        \n",
    "                            id2 = dfpl.query(\"index>@indiceFinal and isPivot==2\").index[0]\n",
    "                            dfpl.loc[id2,'isBreakOutFinal'] = -1\n",
    "                            k=4\n",
    "                        else:\n",
    "                            idfinal = dfpl.index[-1] \n",
    "                            idfinal2 = idfinal+25\n",
    "                            if idfinal2 in df[df['companyName']==ticker].index:\n",
    "                                dfpl2 = df[(df.companyName==ticker)].loc[idfinal+1:idfinal2].copy()\n",
    "                                dfpl = pd.concat([dfpl, dfpl2],ignore_index=False)                           \n",
    "                            else:                  \n",
    "                                dfpl['isBreakOutFinal'] = np.nan\n",
    "    \n",
    "                            k=k+1\n",
    "\n",
    "                \n",
    "                if (df[\"cruce_medias\"][i]==-1):                    \n",
    "                    df.loc[i,'ind_posicion']=-1                    \n",
    "                    df.loc[indiceFinal,'isBreakOutIni']=-1\n",
    "                    df.loc[id2,'isBreakOutFinal']=-1\n",
    "                elif (df[\"cruce_medias\"][i]==1):                        \n",
    "                    df.loc[i,'ind_posicion']=1                   \n",
    "                    df.loc[indiceFinal,'isBreakOutIni']=1\n",
    "                    df.loc[id2,'isBreakOutFinal']=1\n",
    "\n",
    "                #print(\"h5\")\n",
    "                dfpl[\"caso\"] = caso\n",
    "                print(i, df['companyName'][i], \", cruce medias:\",df[\"cruce_medias\"][i],\", slope35:\", sl35, \", slope50:\", sl50)\n",
    "                if len(df_casos)<1:\n",
    "                    df_casos = dfpl\n",
    "                else:\n",
    "                    df_casos = pd.concat([df_casos, dfpl],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d6e01a-2a5b-4811-b55b-4f38199706e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_casos[['companyName', 'caso']].unique()\n",
    "#resultado = df_casos.groupby(['companyName', 'caso'])['Close'].count().reset_index()\n",
    "#resultado[resultado['companyName']==\"META\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f110e7e5-fa3f-4d2b-a80a-4e3d41823e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5472\\799839678.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfpl[\"Datetime_str\"] = dfpl[\"datetime\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#CODIGO DE REVISION CARLOS\n",
    "#dfpl = df.iloc[500:600]\n",
    "dfpl = df[df[\"companyName\"]==\"SPY\"]\n",
    "\n",
    "dfpl[\"Datetime_str\"] = dfpl[\"datetime\"].astype(str)\n",
    "\n",
    "p = figure(width=2500, height=500,\n",
    "        title=\"Canal Bajista - Alcista\",\n",
    "        background_fill_color=\"#efefef\",\n",
    "        tooltips=[(\"Index\", \"@index\"),(\"datetime\", \"@Datetime_str\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\"),\n",
    "                    (\"EMA35\", \"@EMA35\"),\n",
    "                    (\"EMA50\", \"@EMA50\"),\n",
    "                    (\"SMA35\", \"@SMA35\"),\n",
    "                    (\"SMA50\", \"@EMA50\"),\n",
    "                    (\"cdlengulfing\",\"@cdlengulfing\"), \n",
    "                    (\"cdlhammer\",\"@cdlhammer\"), \n",
    "                    (\"cdlmorningstar\",\"@cdlmorningstar\"), \n",
    "                    (\"cdlpiercing\",\"@cdlpiercing\"), \n",
    "                    (\"cdlclosingmarubozu\",\"@cdlclosingmarubozu\"), \n",
    "                    (\"cdlmarubozu\",\"@cdlmarubozu\"), \n",
    "                    (\"cdl3whitesoldiers\",\"@cdl3whitesoldiers\"), \n",
    "                    (\"cdlharami\",\"@cdlharami\"), \n",
    "                    (\"cdlharamicross\",\"@cdlharamicross\"), \n",
    "                    (\"cdlinvertdhammer\",\"@cdlinvertdhammer\"), \n",
    "                    (\"cdlladderbottom\",\"@cdlladderbottom\")]\n",
    "        #tooltips=[(\"Index\", \"@index\"), (\"Open\", \"@Open\"), (\"High\",\"@High\"), (\"Low\",\"@Low\"), (\"Close\",\"@Close\")]\n",
    "        )\n",
    "p.xaxis.major_label_orientation = 0.8 # radians\n",
    "p.x_range.range_padding = 0.05\n",
    "#p.xaxis.axis_line_join = \"bevel\" # radians\n",
    "p.xaxis.axis_line_width = 2\n",
    "\n",
    "p.segment(\"index\", \"High\", \"index\",\"Low\",  color=\"black\", line_width=1, source=dfpl)\n",
    "\n",
    "inc = dfpl.query(\"Close>Open\")\n",
    "dec = dfpl.query(\"Open>Close\")\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"red\",\n",
    "    line_color=\"red\",    \n",
    "    source=dec   \n",
    ")\n",
    "\n",
    "\n",
    "p.vbar(    \n",
    "    x=\"index\",\n",
    "    width=0.6,\n",
    "    bottom=\"Open\",\n",
    "    top=\"Close\",\n",
    "    fill_color=\"green\",\n",
    "    line_color=\"green\", \n",
    "    source=inc   \n",
    ")\n",
    "\n",
    "p.line(\n",
    "    x=\"index\", \n",
    "    y=\"SMA35\", \n",
    "    color=\"white\",\n",
    "    legend_label=\"SMA35\",\n",
    "    source=dfpl)\n",
    "\n",
    "\n",
    "p.line(\n",
    "    x=\"index\", \n",
    "    y=\"SMA50\", \n",
    "    color=\"blue\",\n",
    "    legend_label=\"SMA50\",\n",
    "    source=dfpl)\n",
    "\n",
    "\n",
    "p.line(\n",
    "    x=\"index\", \n",
    "    y=\"EMA35\", \n",
    "    color=\"black\",\n",
    "    legend_label=\"EMA35\",\n",
    "    source=dfpl)\n",
    "\n",
    "\n",
    "p.line(\n",
    "    x=\"index\", \n",
    "    y=\"EMA50\", \n",
    "    color=\"red\",\n",
    "    legend_label=\"EMA50\",\n",
    "    source=dfpl)\n",
    "\n",
    "#p.line(\n",
    "#    x=\"index\", \n",
    "#    y=\"SMA100\", \n",
    "#    color=\"green\",\n",
    "#    legend_label=\"SMA100\",\n",
    "#    source=dfpl)\n",
    "#\n",
    "#p.line(\n",
    "#    x=\"index\", \n",
    "#    y=\"SMA200\", \n",
    "#    color=\"purple\",\n",
    "#    legend_label=\"SMA200\",\n",
    "#    source=dfpl)\n",
    "\n",
    "\n",
    "\n",
    "p.scatter(x=\"index\", y=\"Low\", marker=\"triangle\", size=20,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"inicio1\", source=dfpl[(dfpl.isBreakOutIni==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"High\", marker=\"inverted_triangle\", size=20,\n",
    "           line_color=\"navy\", fill_color=\"red\", alpha=0.5, legend_label=\"inicio2\", source=dfpl[(dfpl.isBreakOutIni==-1)])\n",
    "\n",
    "\n",
    "p.scatter(x=\"index\", y=\"High\", marker=\"inverted_triangle\", size=20,\n",
    "           line_color=\"navy\", fill_color=\"black\", alpha=0.5, legend_label=\"fin1\", source=dfpl[(dfpl.isBreakOutFinal==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"Low\", marker=\"triangle\", size=20,\n",
    "           line_color=\"navy\", fill_color=\"brown\", alpha=0.5, legend_label=\"fin2\", source=dfpl[(dfpl.isBreakOutFinal==-1)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotHigh\", marker=\"circle\", size=5,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista1\", source=dfpl[(dfpl.isPivot==1)])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotLow\", marker=\"circle\", size=5,\n",
    "           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista1\", source=dfpl[(dfpl.isPivot==2)])\n",
    "\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotHigh2\", marker=\"diamond\", size=8,\n",
    "           line_color=\"navy\", fill_color=\"blue\", alpha=0.5, legend_label=\"Cambio Tendencia Bajista2\", source=dfpl[(dfpl.isPivot2==1) & (dfpl.isPivot.isna()) ])\n",
    "\n",
    "p.scatter(x=\"index\", y=\"pivotLow2\", marker=\"diamond\", size=8,\n",
    "           line_color=\"navy\", fill_color=\"green\", alpha=0.5, legend_label=\"Cambio Tendencia Alcista2\", source=dfpl[(dfpl.isPivot2==2) & (dfpl.isPivot.isna())])\n",
    "\n",
    "p.yaxis[0].formatter = NumeralTickFormatter(format=\"$0.00\")\n",
    "p.xaxis.axis_label = \"Fecha\"\n",
    "p.yaxis.axis_label = \"Precio\"\n",
    "p.legend.location=\"top_left\"\n",
    "p.legend.click_policy=\"hide\"\n",
    "\n",
    "#Render linea vertical\n",
    "alza = (dfpl[(dfpl.ind_posicion==1)].index).tolist()\n",
    "baja = (dfpl[(dfpl.ind_posicion==-1)].index).tolist()\n",
    "#vline=Span(source=inicio,dimension='height', line_color='blue',line_width=0.8, line_dash_offset= 0, line_dash='dashed', name=\"hola esto es una prueba\", level='annotation', tags= ['square'])\n",
    "#p.renderers.extend([vline])\n",
    "\n",
    "p.vspan(\n",
    "    x=alza,\n",
    "    line_color=\"blue\"\n",
    ")\n",
    "\n",
    "p.vspan(\n",
    "    x=baja,\n",
    "    line_color=\"red\"\n",
    ")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77343de9-206a-4c0a-b794-84527d04c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "import os\n",
    "#path = r'C:\\Users\\carlo\\OneDrive\\Documentos\\TRADER\\traderapp\\data\\rcb_h.txt'\n",
    "path = r'D:\\traderxpro\\data\\cba_h.txt'\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_casos.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c85ac7-0ab6-49f1-a340-2f5f82d8ae1e",
   "metadata": {},
   "source": [
    "#### BACKTESTING\n",
    "###### Usando paquete backtesting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7373ffcf-9289-4b74-820a-a5b126a365f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\backtesting\\_plotting.py:55: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support, such as old IDEs. Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"b02e2046-7d09-49c0-b33f-6fa87e184a2d\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"b02e2046-7d09-49c0-b33f-6fa87e184a2d\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"b02e2046-7d09-49c0-b33f-6fa87e184a2d\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"b02e2046-7d09-49c0-b33f-6fa87e184a2d\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"b02e2046-7d09-49c0-b33f-6fa87e184a2d\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from backtesting import Backtest, Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6705e2c5-80e0-4ded-8120-9fa22a45f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backTesting = df.copy()\n",
    "df_backTesting.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b5a1e28-b0b7-467c-869b-9ac0fbb13fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategia\n",
    "class strategyCanalBajistaAlcista(Strategy):    \n",
    "    def init(self):        \n",
    "        self.breakout_entry = self.I(lambda x: x, self.data.isBreakOutIni) #Indica la señal entrada al backtesting\n",
    "        self.breakout_exit = self.I(lambda x: x, self.data.isBreakOutFinal) #Indica la señal salida al backtesting\n",
    "\n",
    "    def next(self):       \n",
    "        #print(self.data)        \n",
    "        if self.breakout_entry[-1] == 1:\n",
    "            self.position.close()\n",
    "            self.buy()  #COMPRA\n",
    "        elif self.breakout_entry[-1] == -1:\n",
    "            self.position.close()\n",
    "            self.sell()  #VENTA\n",
    "        elif self.breakout_exit[-1] == 1 and self.position:\n",
    "            self.position.close() #CIERRE\n",
    "        elif self.breakout_exit[-1] == -1 and self.position:\n",
    "            self.position.close() #CIERRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8482c9a-bbd0-4000-85b7-ac6f71071a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3406 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para SPY:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5472\\3604966662.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backtest.run:   0%|          | 0/3480 [00:00<?, ?bar/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para META:\n",
      "<module 'scipy.stats' from 'C:\\\\Users\\\\carlo\\\\anaconda3\\\\Lib\\\\site-packages\\\\scipy\\\\stats\\\\__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5472\\3604966662.py:27: UserWarning: Superimposed OHLC plot matches the original plot. Skipping.\n",
      "  bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")\n"
     ]
    }
   ],
   "source": [
    "# Por cada TIcket\n",
    "my_stats = {}\n",
    "estadisticas = pd.DataFrame()          # lista para ticker\n",
    "tradesprev = pd.DataFrame()     # lista para cada caso por ticker\n",
    "for ticker in df_backTesting['companyName'].unique():\n",
    "    ticker_data = df_backTesting[df_backTesting['companyName'] == ticker].copy() #Filtro por cada ticker\n",
    "    #ticker_data=ticker_data.sort_values(by='caso')\n",
    "    #print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    bt = Backtest(ticker_data, strategyCanalBajistaAlcista, cash=10_000)\n",
    "    #stats = bt.run()\n",
    "    #my_stats[f\"stats_BreakOUT_{ticker}\"] = bt.run()\n",
    "    my_stats = bt.run()\n",
    "    listTrades = my_stats['_trades']\n",
    "    tradesdf = pd.DataFrame(listTrades) #trades\n",
    "    tradesdf['Ticker'] = ticker\n",
    "    my_stast_filter=pd.DataFrame([my_stats])\n",
    "    if tradesprev.shape[0]==0:\n",
    "        tradesprev = tradesdf.copy()\n",
    "        estadisticas=my_stast_filter.copy()\n",
    "    else:\n",
    "        tradesprev = pd.concat([tradesprev, tradesdf],ignore_index=True)\n",
    "        estadisticas = pd.concat([estadisticas, my_stast_filter],ignore_index=True)\n",
    "    # Mostramos\n",
    "    print(f\"Resultados para {ticker}:\")\n",
    "    print(stats)   \n",
    "    #plt.title(f\"Backtest -  {ticker}\")\n",
    "    bt.plot(resample=False, filename=f\"plot_BreakOUT_{ticker}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
